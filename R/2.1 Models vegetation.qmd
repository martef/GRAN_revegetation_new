---
title: "2.1 Models vegetation"
author: "Martef"
format: html
editor: visual
---

# Packages needed

```{r}
library(brms) # bayesian approach to glmm, but with easier steps 
library(posterior) # tools for working with posterior and prior distributions 
library(lme4) # fit GLMM in frequentist framework 
library(tidyverse) # everything for data wrangling 
library(dplyr) # some more for data wrangling 
library(ggplot2) # everything for figures 
library(rstan) 
library(bayesplot) 
library(loo)  
library(sjPlot)
library(insight)
rstan_options(auto_write = TRUE) 
options(mc.cores = parallel::detectCores()) #To Make Stan run faster?
```

# Upload data

```{r}
reveg_var <- read_delim('../data/reveg_var.csv', 
                                  delim = ',',
                                  col_names = TRUE)


```

I haven't fixed the issue with values in Slope and Roughness earlier. These have values from the initial year, but no values for the following years. This value does not change, so should be similar all years.

```{r}
#Fill in values of Slope and Roughness from the initial year unto the following years:
reveg_var <- reveg_var %>%
  group_by(Location, Sublocation, Block, Treatment_ID) %>%
  mutate(
    Roughness = if_else(is.na(Roughness), first(Roughness, order_by = t_year), Roughness),
    Slope = if_else(is.na(Slope), first(Slope, order_by = t_year), Slope)
  ) %>%
  ungroup()
```

```{r}
reveg_var <- reveg_var %>% 
  select( -1) %>%
  mutate_at(c('year', 'month', 'Location', 'Sublocation', 'Block', 'Treatment_ID', 'Treatment', 'Name', 'Station_ID'), as.factor) %>%
  mutate_at(c('Pb', 'Al', 'B', 'Zn', 'Cu', 'Mn', 'Fe', 'P'), as.numeric) %>%
  select('Date','year','month', 'Name','Location','Sublocation', 'Block', 'Treatment', 'Treatment_ID', 'Station_ID', everything()) %>%
  rename(WT_consecutive_days_below = consecutive_days_count, WT_total_days_below=total_days, WT_mean=gs_mean, WT_max=gs_max, WT_min=gs_min) %>%
  rename(NO3_N = 'NO3-N',NH4_N = 'NH4-N')
  

```

# Procedure and goals

## Trying out Bayesian package brms for the GLMM

I want to first figure out what family/distribution I need to work further with and then test specific models towards each other.

The beta distribution is used **to model continuous random variables whose range is between 0 and 1**. For example, in Bayesian analyses, the beta distribution is often used as a prior distribution of the parameter p (which is bounded between 0 and 1) of the binomial distribution.

My cover data range from 0 to 100 percent, but this can easily be displayed as between 0 and 1.

I will test what is best of:

beta + tweeked zeros (0 -\> 0.1) - I can't run a beta with the true values, as I get an error that the values must be greater than 0

zero-inflated-beta + true values

zero-inflated-beta + tweeked zeros (0 -\>0.1)

Then, when figuring out which link I should use for the distribution, I will test these hypotheses:

-   Sphagnum cover is different after 3 years based on treatment

Sphagnum in year 3 \~ Treatment - *This is the simplest model*

-   Sphagnum cover is different between treatments AND increasing with time since treatment (but I only have data from one growth season and then second growth season, so this is meager data)

Sphagnum \~ Treatment + t_year

-   The success of initial Sphagnum cover development is dependent on climatic and abiotic factors (precipitation, temperature, soil temp, water table) during the initial growth season (e.g. prc_season in year 0) or in the early parts of the initial growth season (prc_early in year 0) OR the following year (year 1)

Change_Total \~ Treatment + t_year \* sum_prc_season + t_year \* sum_prc_early + t_year \* consecutive_days_count + t_year \* gs_mean + t_year \* zero_days_season + t_year \* zero_days_early + t_year \* soil_temp

-   The success of initial Sphagnum cover development is dependent on nutrients available in soil
-   

My reason for performing model selection is not to dredge through a large number of possible covariates, but rather to perform inference on exactly two alternative models that represent meaningfully different biological hypotheses/scenarios. I want to know if the evidence strongly favors one hypothesis over the other.

## My models

1.  bayes.brms1 \<- brm(Sphagnum_beta/100 \~ Treatment + year + (1 \| Location/Sublocation/Block), data=reveg_var, family = Beta(link = "logit", link_phi = "log") , WITH ALL PLOTS

2.  bayes.brms2 \<- brm(Sphagnum_beta/100 \~ Treatment + year + (1 \| Location/Sublocation/Block), data=reveg_var, zero_inflated_beta(link = "logit", link_phi = "log", link_zi = "logit"), WITHOUT REFERENCE PLOTS

3.  bayes.brms3 \<- brm(Sphagnum_beta/100 \~ Treatment + t_year (1 \| Location/Sublocation/Block), data=reveg_var, family = Beta(link = "logit", link_phi = "log") ,

4.  bayes.brms4 \<- brm(Sphagnum_beta/100 \~ Treatment + t_year + + WT-variables (1 \| Location/Sublocation/Block), data=reveg_var, zero_inflated_beta(link = "logit", link_phi = "log", link_zi = "logit"), WITHOUT REFERENCE PLOTS AND WITHOUT THE NAs WITHIN WT

5.  

## Posterior predictive checking (PPC)

The idea behind posterior predictive checking is simple: if a model is a good fit then we should be able to use it to generate data that looks a lot like the data we observed.

If the model fits, then replicated data generated under the model should look similar to observed data. To put it another way, the observed data should look plausible under the posterior predictive distribution.

To generate the data used for posterior predictive checks we simulate from the *posterior predictive distribution*. The posterior predictive distribution is the distribution of the outcome variable implied by a model after using the observed data y (a vector of outcome values), and typically predictors X, to update our beliefs about the unknown parameters N8 in the model.

Using the datasets yrep drawn from the posterior predictive distribution, the functions in the **bayesplot** package produce various graphical displays comparing the observed data y to the replications.

# Overall Sphagnum cover

All models run with 4000 iterations with 1000 as warmup and a thinning of 3.

I need to prepare a dataset without the references, or without plots with no WT data (references plus a few sublocations/Stations (HM2 and BSM1, I think), to avoid problems with NAs.

Preparing a dataset without the references

```{r}
reveg_var_noRef <- reveg_var %>%   filter(!Treatment=="R")
```

Preparing a dataset without the reference plots and without plots with no WT data

```{r}
reveg_var_noRef_noNA_WT <- reveg_var_noRef %>%   
  filter(!is.na(WT_mean))  
```

### Model 1

Model run with beta and zero inflated beta distribution i.e. Sphagnum cover tweeked to fit between 0 and 1 with no direct zeros or 1s, over Treatment and t_year.

```{r}
model1.Sph.beta<-   brm(Sphagnum_beta/100 ~ Treatment + t_year + (1 | Location/Sublocation/Block),
                   data=reveg_var,
                 Beta(link = "logit", link_phi = "log"),
                chains = 4, # nb of chains
                 iter = 4000, # nb of iterations, including burnin
                 warmup = 1000, # burnin
                 thin = 3,
                control = list(adapt_delta = 0.99))
```

```{r}
# model1.Sph.zib<-   brm(Sphagnum_beta/100 ~ Treatment + t_year + (1 | Location/Sublocation/Block),
#                    data=reveg_var,
#                    zero_inflated_beta(link = "logit", link_phi = "log", link_zi = "logit"),
#                 chains = 4, # nb of chains
#                  iter = 4000, # nb of iterations, including burnin
#                  warmup = 1000, # burnin
#                  thin = 3,
#                 control = list(adapt_delta = 0.99))
```

```{r}
#saveRDS(model1.Sph.beta, "RDS-files/model1.Sph.beta.RDS")
model1.Sph.beta <- readRDS('RDS-files/model1.Sph.beta.RDS')
#saveRDS(model1.Sph.zib, 'RDS-files/model1.Sph.zib.RDS')
model1.Sph.zib <-readRDS('RDS-files/model1.Sph.zib.RDS')
```

```{r}
summary(model1.Sph.beta)
```

```{r}
summary(model1.Sph.zib)
```

The models run ok, although there is over 40 divergent transitions for model1.beta. Rhat and Bulk_ESS is still ok.

There is 12 divergent transitions for model1.zib, but numbers also ok here.

There is no clear difference between C-M, while C-S and C-R are clearly significant, with much higher Sphagnum levels in the latter two.

There is also a significant positive effect of year since treatment.

```{r}
plot(model1.Sph.beta)
```

```{r}
plot(model1.Sph.zib)
```

There doesn't seem to be any real issues with the transitions, maybe within the Location part of the random variables.

All the levels within the nested random variables are just barely significant.

```{r}
loo_model1.Sph.beta <- loo(model1.Sph.beta)
loo_model1.Sph.zib <- loo(model1.Sph.zib)

loo_compare(loo_model1.Sph.beta, loo_model1.Sph.zib)
```

There is just a tiny difference between the models, with beta being a slightly better fit than zero-inflated beta (elpd-diff -1.1, se 0.1)

## Model 2

Sphagnum cover tweeked to fit between 0 and 1 with no direct 0s and 1s, over Treatment + t_year. None of the reference plots are included..

```{r}
model2.Sph.beta <- brm(Sphagnum_beta/100 ~ Treatment + t_year + (1 | Location/Sublocation/Block),
              data = reveg_var_noRef,
              Beta(link = "logit", link_phi = "log"),
              chains = 4, # nb of chains
              iter = 4000, # nb of iterations, including burnin
              warmup = 1000, # burnin
              thin = 3,
              control = list(adapt_delta = 0.99))
```

```{r}
model2.Sph.zib <- brm(Sphagnum_beta/100 ~ Treatment + t_year + (1 | Location/Sublocation/Block),
              data = reveg_var_noRef,
              family = zero_inflated_beta(link = "logit", link_phi = "log", link_zi = "logit"),
              chains = 4, # nb of chains
              iter = 4000, # nb of iterations, including burnin
              warmup = 1000, # burnin
              thin = 3,
              control = list(adapt_delta = 0.99))

```

These model run ok, with only 5 and 2 divergent transitions.

```{r}
# saveRDS(model2.Sph.beta, "RDS-files/model2.Sph.beta.RDS")
# saveRDS(model2.Sph.zib, 'RDS-files/model2.Sph.zib.RDS')
model2.Sph.beta <- readRDS('RDS-files/model2.Sph.beta.RDS')
model2.Sph.zib <- readRDS('RDS-files/model2.Sph.zib.RDS')
```

```{r}
summary(model2.Sph.beta)
```

All looks good.

Treatment has a significant positive effect (C vs M and C vs S), and much higher between C-S than C-M.

There is a significant positive difference between years.

```{r}
loo_model2.Sph.beta <- loo(model2.Sph.beta)
loo_model2.Sph.zib <- loo(model2.Sph.zib)

loo_compare(loo_model2.Sph.beta, loo_model2.Sph.zib)
```

Same here as with model 1, only a slight difference between the models with beta and zero-inflated beta in favour of beta.

## Model 3

Sphagnum cover tweeked to fit between 0 and 1 with no direct 0s and 1s, over Treatment + t_year + WT-variables. The reference plots and the plots with NAs within WT are excluded.

```{r}
model3.Sph.beta <-   brm(Sphagnum_beta/100 ~ Treatment + t_year + WT_total_days_below + WT_consecutive_days_below + WT_mean + (1 | Location/Sublocation/Block),
                         data = reveg_var_noRef_noNA_WT,
                         Beta(link = "logit", link_phi = "log"),
                         chains = 4, # nb of chains
                         iter = 4000, # nb of iterations, including burnin
                         warmup = 1000, # burnin
                         thin = 3,
                         cores = 4,
                         control = list(adapt_delta = 0.99))
```

```{r}
model3.Sph.zib <- brm(Sphagnum_beta/100 ~ Treatment + t_year + WT_total_days_below + WT_consecutive_days_below + WT_mean +  (1 | Location/Sublocation/Block),
              data = reveg_var_noRef,
              family = zero_inflated_beta(link = "logit", link_phi = "log", link_zi = "logit"),
              chains = 4, # nb of chains
              iter = 4000, # nb of iterations, including burnin
              warmup = 1000, # burnin
              thin = 3,
              control = list(adapt_delta = 0.99))

```

```{r}
#saveRDS(model3.Sph.beta, "RDS-files/model3.Sph.beta.RDS")
model3.Sph.beta <-readRDS('RDS-files/model3.Sph.beta.RDS')


saveRDS(model3.Sph.zib, 'RDS-files/model3.Sph.zib.RDS')
model3.Sph.zib <- readRDS('RDS-files/model3.Sph.zib.RDS')
```

```{r}
summary(model3.Sph.beta)
```

```{r}
plot(model3)
```

All CIs are slightly higher in model 3 compared to model 1 and 2, resulting in C-M being significant in model 3.

There is a slightly negative effect of total days with WT below -20cm, while the amount of consecutive days with WT below -20cm is not significantly impacting.

There is a clear significantly negative effect of low WT (WT_mean).

## Model 4

Sphagnum cover tweeked to fit between 0 and 1 with no direct 0s and 1s, over Treatment + t_year. Without the reference plots and the plots with no water table measurements, so it's comparable to model 2.

```{r}
# model4 <-   brm(Sphagnum_no1/100 ~ Treatment + t_year + (1 | Location/Sublocation/Block),
#                 data=reveg_var_noRef_noNA_WT,
#                 zero_inflated_beta(link = "logit", link_phi = "log", link_zi = "logit"),
#                 chains = 4, # nb of chains
#                 iter = 4000, # nb of iterations, including burnin
#                 warmup = 1000, # burnin
#                 thin = 3,
#                 cores = 4,
#                 control = list(adapt_delta = 0.99))
```

```{r}
#saveRDS(model4, 'RDS-files/model4.Sph.RDS')
readRDS(model4, 'RDS-files/model4.Sph.RDS')
```

```{r}
summary(model4)
```

```{r}
plot(model4)
```

```{r}
loo(model2, model4)
```

```{r}
pp_check(model1, ndraws = 100, type = 'dens_overlay')
```

```{r}
pp_check(model2, ndraws = 100, type = 'dens_overlay')
```

```{r}
pp_check(model3, ndraws = 100, type = 'dens_overlay')
```

```{r}
pp_check(model4, ndraws = 100, type = 'dens_overlay')
```

The PPCs show that the fit of the beta models are generally quite good, but seem to over estimate zeros or low numbers.

Testing model4 with a different distribution

```{r}
model4.beta <-   brm(Sphagnum_nozero/100 ~ Treatment + t_year + (1 | Location/Sublocation/Block),
                data=reveg_var_noRef_noNA_WT,
                Beta(link = "logit", link_phi = "log"),
                chains = 4, # nb of chains
                iter = 4000, # nb of iterations, including burnin
                warmup = 1000, # burnin
                thin = 3,
                cores = 4,
                control = list(adapt_delta = 0.99))
```

```{r}
#saveRDS(model4.beta, 'RDS-files/model4.Sph.beta.RDS')
readRDS(model4.beta, 'RDS-files/model4.Sph.beta.RDS')
```

```{r}
summary(model4.beta)
```

```{r}
pp_check(model4.beta, ndraws = 100, type = 'dens_overlay')
```

```{r}
loo(model4, model4.beta)
```

It seems like the beta model is the better predictor over the zero-inflated beta model.

The elpd diff is 0 to -667 for model4.beta vs model4, i.e. higher score of elpd for the beta model.

I need to rerun the other models with beta distribution as well.

```{r}
model4.nozero <-   brm(Sphagnum_nozero/100 ~ Treatment + t_year + (1 | Location/Sublocation/Block),
                data=reveg_var_noRef_noNA_WT,
                zero_inflated_beta(link = "logit", link_phi = "log", link_zi = "logit"),
                chains = 4, # nb of chains
                iter = 4000, # nb of iterations, including burnin
                warmup = 1000, # burnin
                thin = 3,
                cores = 4,
                control = list(adapt_delta = 0.99))
```

```{r}
pp_check(model4.nozero, ndraws = 100, type = 'dens_overlay')
```

```{r}
loo(model4, model4.beta, model4.nozero)
```

```{r}
model3.beta <-   brm(Sphagnum_nozero/100 ~ Treatment + t_year + (1 | Location/Sublocation/Block),
              data=reveg_var_noRef,
              Beta(link = "logit", link_phi = "log"),
              chains = 4, # nb of chains
              iter = 4000, # nb of iterations, including burnin
              warmup = 1000, # burnin
              thin = 3,
              cores = 4,
              control = list(adapt_delta = 0.99))
```

```{r}
summary(model3.beta)
```

```{r}
pp_check(model3.beta, ndraws = 100, type = 'dens_overlay')
```

```{r}
loo(model3, model3.beta)
```

```{r}
model1.beta <-   brm(Sphagnum_no1/100 ~ Treatment + t_year + (1 | Location/Sublocation/Block),
                   data=reveg_var,
                   Beta(link = "logit", link_phi = "log"),
                chains = 4, # nb of chains
                 iter = 4000, # nb of iterations, including burnin
                 warmup = 1000, # burnin
                 thin = 3,
                control = list(adapt_delta = 0.99))
```

## Model 5

# Overall Sphagnum cover only in year 3

## Model 1

## Model 2

## Model 3

## Model 4

## Model 5

## Model 5

# Overall Sphagnum cover CHANGE

Running the models again, but now with only the difference between year 0 and year 3, and dropping year as an explanation variable.

Altering the Change_Total variable to not include true 100 (1s) and less than 0 (minus). This only accounts for 4 values below 0, that barely are minus (-0.4 and -0.9) and wouldn't make such a big impact.

```{r}
reveg_var <- reveg_var %>%
  mutate(Change_Total_no1=case_when(Change_Total<0 ~ 0,
                                    Change_Total==100.0 ~ 99.9,
                                    TRUE ~ Change_Total))
```

```{r}
reveg_var_noRef <- reveg_var_noRef %>%
  mutate(Change_Total_no1=case_when(Change_Total<0 ~ 0,
                                    Change_Total==100.0 ~ 99.9,
                                    TRUE ~ Change_Total))
```

```{r}
reveg_var %>%
  filter(!is.na(Change_Total)) %>%  # Exclude NA values in the Sphagnum column
  ggplot(aes(x = Change_Total)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Sphagnum Cover Change Values",
       x = "Sphagnum Cover Change",
       y = "Frequency")
```

```{r}
reveg_var %>%
  filter(!is.na(Change_Total)) %>%  # Exclude NA values in the Sphagnum column
  ggplot(aes(x = Change_Total)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Sphagnum Cover Change Values",
       x = "Sphagnum Cover Change",
       y = "Frequency") +
  facet_wrap(~Treatment)
```

```{r}
reveg_var %>%
  filter(Treatment=='R') %>%
  select(Change_Total)
```

The values seem to be quite normally distributed.

## Model 1

```{r}
model1.change <-   brm(Change_Total_no1/100 ~ Treatment + (1 | Location/Sublocation/Block),                  
                    data=reveg_var,
                    zero_inflated_beta(link = "logit", link_phi = "log", link_zi = "logit"),
                 chains = 4, # nb of chains
                  iter = 4000, # nb of iterations, including burnin
                  warmup = 1000, # burnin
                thin = 3,
              cores = 4,
                  control = list(adapt_delta = 0.99))
```

```{r}
#saveRDS(model1.change, 'RDS-files/model1.Sph.change.RDS')
readRDS(model1.change, 'RDS-files/model1.Sph.change.RDS')
```

```{r}
summary(model1.change)
```

```{r}
plot(model1.change)
```

```{r}
pp_check(model1.change, ndraws = 100, type = 'dens_overlay')
```
