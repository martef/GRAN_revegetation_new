---
title: "Updates with corrected WT at BSM"
author: "MarteF"
format: html
editor: visual
---

## Packages needed

```{r}
library(readr)
library(lubridate)
library(scales)
library(gridExtra)
library(timetk)
library(brms) # bayesian approach to glmm, but with easier steps 
library(posterior) # tools for working with posterior and prior distributions 
library(lme4) # fit GLMM in frequentist framework 
library(tidyverse) # everything for data wrangling (included ggplot2)
library(dplyr) # some more for data wrangling 
library(rstan) 
library(bayesplot) 
library(loo)  
library(sjPlot)
library(insight)
library(ggridges)
library(ggrepel)
library(cowplot)
library(tidybayes)
library(openxlsx)

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

```{r}
citation()
```

# WT adjustments and rerunning of code to create WT variables

```{r}
wt_all <- readr::read_delim('../data/wt_all.csv', 
                                  delim = ',',
                                  col_names = TRUE)

#Filter data for growth season
wt_season <- wt_all %>%     
  filter((year >= 2020 & year < 2023) & (month >= 5 & month <= 9) | (year == 2023) & (month >= 5 & month<9))

#Create julian date column
wt_season$jday <- yday(wt_season$Date)
wt_season$month_name <- format(wt_season$Date,"%B")
wt_season$month_name <- factor(wt_season$month_name, levels = month.name)

#Filter out the malfunctioning stations
wt_season <- wt_season %>%
  filter(!(year %in%  c('2022', '2023') & Station_ID=='BSM1')) %>%
  filter(Station_ID!='HM2')
```

## Adjust the values of BSM1, BSM2, BSM3

Adjusting the WT levels at the stations that clearly are giving a too low reading, as the real time measurements aren't equal, and the data indicate a "roof" at about -10cm, where a zero (or maybe even a few plus) clearly should have been. Adjusting the levels by subtracking the measured maximum to at least get level 0 readings.

```{r}
#Checking max level
wt_season %>%
  filter(Station_ID=='BSM1') %>%
        summarise(max=max(LEVEL))

# I don't have realtime data for this station, as it was malfunctioning in 2022 (when I did realtime measurements)

# Filter data for the desired Station_IDs
adjusted_data_BSM1 <- wt_season%>%
  filter(Station_ID %in% c("BSM1")) %>%
  group_by(Station_ID) %>%
  mutate(LEVEL = LEVEL - max(LEVEL)) %>%
  ungroup()

# View the adjusted data
print(adjusted_data_BSM1)
```

```{r}
wt_season %>%
  filter(Station_ID %in% c('BSM1')) %>%
  group_by(Station_ID)
```

The WT levels are now adjusted by about 7 cm at BSM1.

```{r}

#Checking max level
wt_season %>%
  filter(Station_ID=='BSM2') %>%
        summarise(max=max(LEVEL))

#Checking levels at 22/6-22, when I have realtime data
wt_season %>%
  filter(Station_ID=='BSM2', Date == as.Date("2022-06-22"))

# Filter data for the desired Station_IDs         
adjusted_data_BSM2 <- wt_season%>%
  filter(Station_ID %in% c("BSM2")) %>%
  group_by(Station_ID) %>%
  mutate(LEVEL = LEVEL - max(LEVEL)) %>%
  ungroup()

# View the adjusted data
print(adjusted_data_BSM2)
```

```{r}
wt_season %>%
  filter(Station_ID %in% c('BSM2')) %>%
  group_by(Station_ID)
```

The WT levels are now adjusted with approx 3 cm.

```{r}
#Checking max level
wt_season %>%
  filter(Station_ID=='BSM3') %>%
        summarise(max=max(LEVEL))

#Checking levels at 22/6-22, when I have realtime data
wt_season %>%
  filter(Station_ID=='BSM3', Date == as.Date("2022-06-22"))

# Filter data for the desired Station_IDs         
adjusted_data_BSM3 <- wt_season%>%
  filter(Station_ID %in% c("BSM3")) %>%
  group_by(Station_ID) %>%
  mutate(LEVEL = LEVEL - max(LEVEL)) %>%
  ungroup()

# View the adjusted data
print(adjusted_data_BSM3)
```

```{r}
wt_season %>%
  filter(Station_ID %in% c('BSM3')) %>%
  group_by(Station_ID)
```

The WT levels are now adjusted with approx. 4 cm.

All of these adjustments are very conservative. I think the true valued would be even somewhat higher.

Now to combine the adjusted data with the full dataset

```{r}
# Combine adjusted data with the rest of the dataset
wt_season_rev <- wt_season %>%
  filter(!Station_ID %in% c("BSM1", "BSM2", "BSM3")) %>% #remove original data
  bind_rows(adjusted_data_BSM1, adjusted_data_BSM2, adjusted_data_BSM3) #add adjusted data
```

## Create new variables

```{r}
#Daily means of WT values
wt_daily_means <- wt_season_rev %>%
  mutate(Location = case_when(
    grepl("^BSM", Station_ID) ~ "BSM",
    grepl("^VSM", Station_ID) ~ "VSM",
    grepl("^HM", Station_ID) ~ "HM",
    TRUE ~ NA_character_  # This handles any cases not matching the specified pattern
  )) %>%
  group_by(Station_ID, Location, jday, month, month_name, year) %>%
 summarise_by_time(.date_var=DateTime,
                    .by="day",
                    daily_mean = mean(LEVEL), daily_max = max(LEVEL), daily_min= min(LEVEL))

wt_daily_means
```

```{r}
#Summary per growth season
gs_wt <-wt_daily_means%>%
  group_by(Station_ID, year)%>%
  summarise_by_time(.date_var=DateTime,
                    .by="year", gs_mean = mean(daily_mean), gs_max = max(daily_max), gs_min = min(daily_min) )
gs_wt
```

```{r}
# Create variable for days below -20cm WT within growth season
wt_daily_means <- wt_daily_means %>%
  mutate(year=as.factor(year(DateTime))) %>%
  mutate(month=as.factor(month(DateTime)))

total_days_below_minus_0.2 <- wt_daily_means %>% 
  filter(daily_mean < -0.2) %>% 
  group_by(Station_ID, year) %>% 
  summarise(total_days = n_distinct(DateTime))%>%
  ungroup()%>%
 complete(Station_ID, year, fill = list(total_days = 0)) %>%
ungroup()
print(total_days_below_minus_0.2, n = Inf)

# Create a data frame with all combinations of year, month, and Station_ID
all_combinations <- expand.grid(
  year = unique(wt_daily_means$year),
  Station_ID = unique(wt_daily_means$Station_ID)
)

# Join the data frame with all combinations with the calculated data
total_days_below_minus_0.2_complete <- left_join(all_combinations, total_days_below_minus_0.2, by = c("year", "Station_ID"))
total_days_below_minus_0.2_complete$total_days[is.na(total_days_below_minus_0.2_complete$total_days)] <- 0

#This is not perfect, as it creates zeros for years that were not measured. BSM was not measured in 2020.

total_days_below_minus_0.2_complete <- total_days_below_minus_0.2_complete %>%
   filter(!(Station_ID %in% c("BSM1", "BSM2", "BSM3") & year == '2020'))

total_days_below_minus_0.2_complete
```

```{r}
#Create variable for max no of consecutive days wit WT <-0.2 within growth season
df <- wt_daily_means %>%
  mutate(consecutive_days = daily_mean < -0.2) %>%
  group_by(Station_ID, year) %>%
  mutate(consecutive_days = cumsum(consecutive_days) - cummax((!consecutive_days) * cumsum(consecutive_days))) %>%
  ungroup()

result <- df %>%
  group_by(Station_ID, year) %>%
  summarise(consecutive_days_count = max(consecutive_days)) %>%
  ungroup()

result
```

```{r}
#Combine variables for growth season
gs_wt <- gs_wt %>% 
  select(-c('DateTime')) %>%
  mutate(year=as.factor(year))


wt_variables <- result %>%
  full_join(gs_wt, by=c('Station_ID','year'))
wt_variables <- wt_variables %>%
  full_join(total_days_below_minus_0.2_complete, by=c('Station_ID', 'year'))

wt_variables %>%
  rename(consecutive_days_low_gs = consecutive_days_count, total_days_low_gs = total_days)

wtvar <- wt_variables 
wtvar <- wtvar %>%  
     mutate(Name=case_when(Station_ID=='BSM1'~ 'Hoydalsmoan', 
                           Station_ID=='BSM2'~'Hoydalsmoan',
                           Station_ID=='BSM3'~'Hoydalsmoan', 
                           Station_ID=='HM1'~'Hoydalsmoan', 
                           Station_ID=='HM2'~'Hoydalsmoan', 
                           Station_ID=='HM3'~'Hoydalsmoan', 
                           Station_ID=='VSM1'~'Vestersetermyra', 
                           Station_ID=='VSM2'~'Vestersetermyra', 
                           TRUE ~ NA)) %>% 
  mutate_at(c('year', 'Station_ID'), as.factor) 

#Created a column for weather station Name in the water table dataset


wtvar <- wtvar%>% 
   relocate(Name) 

# The total days with water table < -0.2m (total_days) are set to zero for those stations that didn't have any data (BSM1 in 2022, 2023, and HM2 in 2021, 2022, 2023). I need to change these to NAs 

wtvar <- wtvar %>% 
  mutate(total_days = case_when( 
         is.na(consecutive_days_count) ~ NA_real_, 
              TRUE ~ total_days 
            )) 
 
#Create similar columns as in reveg dataset 
wtvar <- wtvar %>% 
     separate('Station_ID', into = c('Location', 'Sublocation'), sep = "(?<=\\D)(?=\\d)|(?<=\\d)(?=\\D)", remove = FALSE)

#7write.csv(wtvar, '../data/WT_varfinal.csv')
#wtvar <- readr::read_delim('../data/WT_varfinal.csv',
 #                      delim =  ',',
  #                    col_names = TRUE)
wtvar
```

## Summary of WT variables

```{r}
wt_variables_loc <- wt_variables %>%
mutate(Location = case_when(
    grepl("^BSM", Station_ID) ~ "BSM",
    grepl("^VSM", Station_ID) ~ "VSM",
    grepl("^HM", Station_ID) ~ "HM",
    TRUE ~ NA_character_  # This handles any cases not matching the specified patterns
  )) %>%
  group_by(Location, year) %>%
  summarise(max_WT_below_cons = max(consecutive_days_count, na.rm=TRUE),
            WT_mean = mean(gs_mean, na.rm = TRUE),
            WT_max = max(gs_max, na.rm = TRUE),
            WT_min = min(gs_min, na.rm = TRUE),
            total_days_below = max(total_days, na.rm=TRUE))
wt_variables_loc
```

```{r}
wt_variables_subloc <- wt_variables %>%
  group_by(Station_ID, year) %>%
  summarise(max_WT_below_cons = max(consecutive_days_count, na.rm=TRUE),
            WT_mean = mean(gs_mean, na.rm = TRUE),
            WT_max = max(gs_max, na.rm = TRUE),
            WT_min = min(gs_min, na.rm = TRUE),
            total_days_below = max(total_days, na.rm=TRUE))
wt_variables_loc
```

# Correlation test of WT variables

```{r}
# Perform correlation test
cor_matrix <- wtvar %>%
  select(consecutive_days_count, gs_mean, gs_max, gs_min, total_days) %>%
  cor(use = "complete.obs", method = "pearson")

# Display the correlation matrix
print(cor_matrix)
```

```{r}
library(car)

# Fit a linear model with all the variables
lm_model <- lm(gs_mean ~ consecutive_days_count + gs_max + gs_min + total_days, data = wtvar)

# Calculate VIF
vif_values <- vif(lm_model)

# Display the VIF values
print(vif_values)
```

From the Pearson's correlation test and the Variance Inflation Factor (VIF) test, I can see that I'll probably should only use one of the WT variables, possibly mean. I could also test with adding max.

## Combine WT with precipitation

```{r}
climdat_season <- readr::read_delim('../data/climdat_season.csv',
                       delim =  ',',
                      col_names = TRUE)

#rename columns in climdat_season
climdat_season <- climdat_season %>%
  rename(clim_station = Name, Date = Time) %>%
  mutate(across(c('year', 'month'), as.factor))

#Create column for the weather station in the wt_daily_means dataset
wt_daily_means <- wt_daily_means %>%
  mutate(clim_station = case_when(Location== 'VSM' ~ 'Vestersetermyra',
                         Location=='HM' ~ 'Hoydalsmoan',
                         Location == 'BSM' ~ 'Hoydalsmoan',
                                TRUE ~ NA))

#rename columns in wt_daily_means
wt_daily_means <- wt_daily_means %>%
  rename(Date=DateTime)

#join climate and WT
clim_wt <- wt_daily_means %>%
  left_join(climdat_season, by=c('clim_station', 'Date', 'year', 'month', 'jday', 'month_name'))

clim_wt_combined <- clim_wt %>%
  group_by(Station_ID, Location, clim_station, Date, jday, month_name, year, Year, month, Month) %>%
  summarize(
    WT_daily_mean = mean(daily_mean, na.rm = TRUE),
    WT_daily_max = mean(daily_max, na.rm = TRUE),
    WT_daily_min = mean(daily_min, na.rm = TRUE),
    max_temp = first(Max_temp),  # Adjust this function based on your needs
    mean_temp = first(Mean_temp),
    min_temp = first(Min_temp),
    prec = last(Precipitation))

rm(clim_wt)

#write.csv(clim_wt_combined, file = '../data/clim_wt_combined2.csv')
clim_wt_combined
```

```{r}
plot_BSM2 <- clim_wt_combined %>%
  filter(Station_ID == "BSM2", Date >= as.Date("2021-05-01") & Date <= as.Date("2021-09-30")) %>%
  ggplot(aes(x = Date)) +
    # WT_daily_mean as blue line underneath surface at 0m
    geom_line(aes(y = WT_daily_mean), color= "darkblue", size= 1) +
    # prec as bars going upward from 0
    geom_bar(aes(y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
    scale_y_continuous(
      name = "Mean WT (m)",
      limits = c(-0.60, 0.60),
       breaks = seq(-0.60, 0.60, by = 0.15),
      labels = function(x) ifelse(x > 0.15, "", x),  # Hide labels for values > 0.15
      sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(0, 40, 5))
    ) +
    labs(title = paste("Mean WT and precipitation per day during growth season 2020 for BSM2"),
         x = "Date", y = "Mean WT") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

#ggsave(filename = '../figures/WT_prec_BSM2.png', plot = plot_BSM2)
plot_BSM2
```

## Reprint all WT and prec figures

```{r}

# Filter the data for the desired time period
filtered_data <- clim_wt_combined %>%
  filter(Date >= as.Date("2020-05-01") & Date <= as.Date("2020-09-30"))

# Get unique Station_IDs
unique_stations <- unique(filtered_data$Station_ID)

# Create a separate figure for each Station_ID
for (station in unique_stations) {
  station_data <- filtered_data %>%
    filter(Station_ID == station)

  station_comb_plot <- ggplot(station_data, aes(x = Date)) +
    # WT_daily_mean as blue line underneath surface at 0m
    geom_line(aes(y = WT_daily_mean), color= "darkblue", size= 1) +
    # prec as bars going upward from 0
    geom_bar(aes(y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
    scale_y_continuous(
      name = "Mean WT (m)",
      limits = c(-0.60, 0.80),
       breaks = seq(-0.60, 0.80, by = 0.10),
      labels = function(x) ifelse(x > 0.15, "", sprintf("%.2f", x)),  # Format numbers with two decimal places  # Hide labels for values > 0.15
      sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(0, 60, 10))
    ) +
    labs(title = paste("Mean WT and precipitation per day during growth season 2020 for", station),
         x = "Date", y = "Mean WT") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Save the plot as a PNG file
  ggsave(filename = paste0("../figures/WT_prec_2020", station, ".png"), plot = station_comb_plot, width = 10, height = 6)

  print(station_comb_plot)
}
```

Then repeat for the other years:

```{r}
# Filter the data for the desired time period
filtered_data <- clim_wt_combined %>%
  filter(Date >= as.Date("2021-05-01") & Date <= as.Date("2021-09-30"))

# Get unique Station_IDs
unique_stations <- unique(filtered_data$Station_ID)

# Create a separate figure for each Station_ID
for (station in unique_stations) {
  station_data <- filtered_data %>%
    filter(Station_ID == station)

  station_comb_plot <- ggplot(station_data, aes(x = Date)) +
    # WT_daily_mean as blue line underneath surface at 0m
    geom_line(aes(y = WT_daily_mean), color= "darkblue", size= 1) +
    # prec as bars going upward from 0
    geom_bar(aes(y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
    scale_y_continuous(
      name = "Mean WT (m)",
      limits = c(-0.60, 1.8),
       breaks = seq(-0.60, 1.8, by = 0.10),
      labels = function(x) ifelse(x > 0.15, "", sprintf("%.2f", x)),  # Format numbers with two decimal places  # Hide labels for values > 0.15
      sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(0, 110, 10))
    ) +
    labs(title = paste("Mean WT and precipitation per day during growth season 2021 for", station),
         x = "Date", y = "Mean WT") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Save the plot as a PNG file
  ggsave(filename = paste0("../figures/WT_prec_2021", station, ".png"), plot = station_comb_plot, width = 10, height = 6)

  print(station_comb_plot)
}
```

```{r}

# Filter the data for the desired time period
filtered_data <- clim_wt_combined %>%
  filter(Date >= as.Date("2022-05-01") & Date <= as.Date("2022-09-30"))

# Get unique Station_IDs
unique_stations <- unique(filtered_data$Station_ID)

# Create a separate figure for each Station_ID
for (station in unique_stations) {
  station_data <- filtered_data %>%
    filter(Station_ID == station)

  station_comb_plot <- ggplot(station_data, aes(x = Date)) +
    # WT_daily_mean as blue line underneath surface at 0m
    geom_line(aes(y = WT_daily_mean), color= "darkblue", size= 1) +
    # prec as bars going upward from 0
    geom_bar(aes(y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
    scale_y_continuous(
      name = "Mean WT (m)",
      limits = c(-0.60, 1.150),
       breaks = seq(-0.60, 1.150, by = 0.10),
      labels = function(x) ifelse(x > 0.15, "", sprintf("%.2f", x)),  # Format numbers with two decimal places  # Hide labels for values > 0.15
      sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(0, 80, 10))
    ) +
    labs(title = paste("Mean WT and precipitation per day during growth season 2022 for", station),
         x = "Date", y = "Mean WT") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Save the plot as a PNG file
  ggsave(filename = paste0("../figures/WT_prec_2022", station, ".png"), plot = station_comb_plot, width = 10, height = 6)

  print(station_comb_plot)
}
```

```{r}

# Filter the data for the desired time period
filtered_data <- clim_wt_combined %>%
  filter(Date >= as.Date("2023-05-01") & Date <= as.Date("2023-09-30"))

# Get unique Station_IDs
unique_stations <- unique(filtered_data$Station_ID)

# Create a separate figure for each Station_ID
for (station in unique_stations) {
  station_data <- filtered_data %>%
    filter(Station_ID == station)

  station_comb_plot <- ggplot(station_data, aes(x = Date)) +
    # WT_daily_mean as blue line underneath surface at 0m
    geom_line(aes(y = WT_daily_mean), color= "darkblue", size= 1) +
    # prec as bars going upward from 0
    geom_bar(aes(y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
    scale_y_continuous(
      name = "Mean WT (m)",
      limits = c(-0.60, 0.8),
       breaks = seq(-0.60, 0.8, by = 0.10),
      labels = function(x) ifelse(x > 0.15, "", sprintf("%.2f", x)),  # Format numbers with two decimal places  # Hide labels for values > 0.15
      sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(0, 50, 10))
    ) +
    labs(title = paste("Mean WT and precipitation per day during growth season 2023 for", station),
         x = "Date", y = "Mean WT") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

  # Save the plot as a PNG file
  ggsave(filename = paste0("../figures/WT_prec_2023", station, ".png"), plot = station_comb_plot, width = 10, height = 6)

  print(station_comb_plot)
}
```

## A single plot for 2020 and VSM:

```{r}
# Filter the data for the desired time period and Station_IDs VSM1 and VSM2
VSM_data <- clim_wt_combined %>%
  filter(Date >= as.Date("2020-05-01") & Date <= as.Date("2020-09-30"),
         Station_ID %in% c("VSM1", "VSM2"))

# Since precipitation is the same for both VSM1 and VSM2, we only need to illustrate it once.
# Create a separate dataset for precipitation
VSM_prec_data <- VSM_data %>%
  filter(Station_ID == "VSM1")

# Create the plot for Station_IDs VSM1 and VSM2
VSM_comb_plot <- ggplot() +
  # WT_daily_mean as blue line underneath surface at 0m
  geom_line(data = VSM_data, aes(x = Date, y = WT_daily_mean, color = Station_ID), size = 1) +
  # prec as bars going upward from 0 (using only VSM1 for precipitation)
  geom_bar(data = VSM_prec_data, aes(x = Date, y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
  scale_y_continuous(
    name = "Mean WT (m)",
    limits = c(-0.60, 0.80),
    breaks = seq(-0.60, 0.80, by = 0.10),
    labels = function(x) ifelse(x > 0.15, "", sprintf("%.2f", x)),  # Format numbers with two decimal places, hide labels for values > 0.15
    sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(0, 60, 10))
  ) +
  labs(title = "Mean WT and precipitation per day during first growing season for VSM1 and VSM2",
       x = "Date", y = "Mean WT") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_manual(values = c("VSM1" = "darkblue", "VSM2" = "darkgreen"))

# Save the plot as a PNG file
ggsave(filename = "../figures/WT_prec_2020_VSM1_VSM2.png", plot = VSM_comb_plot, width = 10, height = 6)

# Print the plot
print(VSM_comb_plot)
```

## Similar plot for HM 2020:

```{r}
# Filter the data for the desired time period and Station_IDs VSM1 and VSM2
HM_data <- clim_wt_combined %>%
  filter(Date >= as.Date("2020-05-01") & Date <= as.Date("2020-09-30"),
         Station_ID %in% c("HM1", "HM3"))

# Since precipitation is the same for both VSM1 and VSM2, we only need to illustrate it once.
# Create a separate dataset for precipitation
HM_prec_data <- HM_data %>%
  filter(Station_ID == "HM1")

# Create the plot for Station_IDs VSM1 and VSM2
HM_comb_plot <- ggplot() +
  # WT_daily_mean as blue line underneath surface at 0m
  geom_line(data = HM_data, aes(x = Date, y = WT_daily_mean, color = Station_ID), size = 1) +
  # prec as bars going upward from 0 (using only VSM1 for precipitation)
  geom_bar(data = HM_prec_data, aes(x = Date, y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
  scale_y_continuous(
    name = "Mean WT (m)",
    limits = c(-0.60, 0.80),
    breaks = seq(-0.60, 0.80, by = 0.10),
    labels = function(x) ifelse(x > 0.15, "", sprintf("%.2f", x)),  # Format numbers with two decimal places, hide labels for values > 0.15
    sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(0, 60, 10))
  ) +
  labs(title = "Mean WT and precipitation per day during first growing season for HM1 and HM3",
       x = "Date", y = "Mean WT") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_manual(values = c("HM1" = "darkblue", "HM3" = "darkgreen"))

# Save the plot as a PNG file
ggsave(filename = "../figures/WT_prec_2020_HM-all.png", plot = HM_comb_plot, width = 10, height = 6)

# Print the plot
print(HM_comb_plot)
```

```{r}
# Filter the data for the desired time period and Station_IDs VSM1 and VSM2
VSM_data2 <- clim_wt_combined %>%
  filter(Date >= as.Date("2021-05-01") & Date <= as.Date("2021-09-30"),
         Station_ID %in% c("VSM1", "VSM2"))

# Since precipitation is the same for both VSM1 and VSM2, we only need to illustrate it once.
# Create a separate dataset for precipitation
VSM_prec_data2 <- VSM_data2 %>%
  filter(Station_ID == "VSM1")

# Create the plot for Station_IDs VSM1 and VSM2
VSM_comb_plot2 <- ggplot() +
  # WT_daily_mean as blue line underneath surface at 0m
  geom_line(data = VSM_data2, aes(x = Date, y = WT_daily_mean, color = Station_ID), size = 1) +
  # prec as bars going upward from 0 (using only VSM1 for precipitation)
  geom_bar(data = VSM_prec_data2, aes(x = Date, y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
  scale_y_continuous(
    name = "Mean WT (m)",
    limits = c(-0.60, 0.80),
    breaks = seq(-0.60, 0.80, by = 0.10),
    labels = function(x) ifelse(x > 0.15, "", sprintf("%.2f", x)),  # Format numbers with two decimal places, hide labels for values > 0.15
    sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(0, 60, 10))
  ) +
  labs(title = "Mean WT and precipitation per day during second growing season for VSM1 and VSM2",
       x = "Date", y = "Mean WT") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_manual(values = c("VSM1" = "darkblue", "VSM2" = "darkgreen"))

# Save the plot as a PNG file
ggsave(filename = "../figures/WT_prec_2021_VSM1_VSM2.png", plot = VSM_comb_plot2, width = 10, height = 6)

# Print the plot
print(VSM_comb_plot2)
```

```{r}
# Filter the data for the desired time period and Station_IDs VSM1 and VSM2
VSM_data3 <- clim_wt_combined %>%
  filter(Date >= as.Date("2022-05-01") & Date <= as.Date("2022-09-30"),
         Station_ID %in% c("VSM1", "VSM2"))

# Since precipitation is the same for both VSM1 and VSM2, we only need to illustrate it once.
# Create a separate dataset for precipitation
VSM_prec_data3 <- VSM_data3 %>%
  filter(Station_ID == "VSM1")

# Create the plot for Station_IDs VSM1 and VSM2
VSM_comb_plot3 <- ggplot() +
  # WT_daily_mean as blue line underneath surface at 0m
  geom_line(data = VSM_data3, aes(x = Date, y = WT_daily_mean, color = Station_ID), size = 1) +
  # prec as bars going upward from 0 (using only VSM1 for precipitation)
  geom_bar(data = VSM_prec_data3, aes(x = Date, y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
  scale_y_continuous(
    name = "Mean WT (m)",
    limits = c(-0.60, 0.80),
    breaks = seq(-0.60, 0.80, by = 0.10),
    labels = function(x) ifelse(x > 0.15, "", sprintf("%.2f", x)),  # Format numbers with two decimal places, hide labels for values > 0.15
    sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(0, 60, 10))
  ) +
  labs(title = "Mean WT and precipitation per day during third growing season for VSM1 and VSM2",
       x = "Date", y = "Mean WT") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_manual(values = c("VSM1" = "darkblue", "VSM2" = "darkgreen"))

# Save the plot as a PNG file
ggsave(filename = "../figures/WT_prec_2022_VSM1_VSM2.png", plot = VSM_comb_plot3, width = 10, height = 6)

# Print the plot
print(VSM_comb_plot3)
```

# Calculate number of days with/without \>2mm precipitation within growing season

```{r}
# Filter for the time period and count days with precipitation > 2mm per Location and Year
prec_days_per_location_year <- climdat_season %>%
  filter(Precipitation >= 2) %>%
  group_by(clim_station, year) %>%
  summarise(n_days_prec_above_2mm = n(), .groups = "drop")

# Display result
prec_days_per_location_year
```

```{r}
# Filter dataset based on the required conditions and rename locations
summary_month_prec <- climdat_season %>%
  filter((clim_station == "Hoydalsmoan" & year == 2020) |
         (clim_station == "Hoydalsmoan" & year == 2021) |
         (clim_station == "Vestersetermyra" & year == 2020)) %>%
  mutate(Location = case_when(
    clim_station == "Hoydalsmoan" & year == 2020 ~ "HM",
    clim_station == "Hoydalsmoan" & year == 2021 ~ "BSM",
    clim_station == "Vestersetermyra" & year == 2020 ~ "VSM"
  )) %>%
  filter(month %in% c(5, 6, 7, 8, 9)) %>%  # Keep only growing season months
  group_by(Location, year, month) %>%
  summarise(n_days_prec_above_2mm = sum(Precipitation >= 2, na.rm = TRUE), .groups = "drop")

# Display result
summary_month_prec
```

```{r}

# Filter dataset and rename Locations
filtered_prec_data <- climdat_season %>%
  filter((clim_station == "Hoydalsmoan" & year == 2020) |
         (clim_station == "Hoydalsmoan" & year == 2021) |
         (clim_station == "Vestersetermyra" & year == 2020)) %>%
  mutate(Location = case_when(
    clim_station == "Hoydalsmoan" & year == 2020 ~ "HM",
    clim_station == "Hoydalsmoan" & year == 2021 ~ "BSM",
    clim_station == "Vestersetermyra" & year == 2020 ~ "VSM"
  )) %>%
  filter(month %in% c(5, 6, 7, 8, 9))  # Keep only growing season months

# Calculate consecutive days with precipitation < 2mm, treating NAs as FALSE (not counted)
consecutive_prec <- filtered_prec_data %>%
  mutate(prec_below_2mm = Precipitation < 2) %>%   # Logical variable
  replace_na(list(prec_below_2mm = FALSE)) %>%  # Replace NA with FALSE
  group_by(Location, year, month) %>%
  mutate(consecutive_days = cumsum(prec_below_2mm) - cummax((!prec_below_2mm) * cumsum(prec_below_2mm))) %>%
  ungroup()

# Summarize maximum consecutive days per month
max_consecutive_prec <- consecutive_prec %>%
  group_by(Location, year, month) %>%
  summarise(max_consecutive_days = max(consecutive_days, na.rm = TRUE), .groups = "drop")

# Display result
max_consecutive_prec
```

```{r}
# Define the output file name
output_file <- "effective_prec2.xlsx"

# Create a list of data frames to save in separate sheets
data_list <- list(
  "Growing_Season_Days" = summary_month_prec,
  "Precip_Days" = prec_days_per_location_year,
  "Max_Cons_Days" = max_consecutive_prec
)

# Write to an Excel file with multiple sheets
write.xlsx(data_list, file = output_file)

# Message to indicate success
cat("Excel file saved as", output_file)
```

```{r}
getwd()
```

# Upload reveg and join with WT

```{r}
reveg_var <- readr::read_delim('../data/reveg_var.csv', 
                                  delim = ',',
                                  col_names = TRUE)

reveg_wt <- reveg_var %>%
  select(c(Date:Other, Change_Year:Sphagnum_beta)) %>%
  mutate_at(c('Location','Sublocation', 'Treatment_ID', 'Treatment', 'year', 'Block' ), as.factor)

#Join the revegetation dataset with the variable datasets

reveg_wt <- reveg_wt %>%
   left_join(wtvar, by=c('Location', 'Sublocation', 'year'))

reveg_wt <- reveg_wt %>%
   mutate_at(c('Location','Sublocation', 'Treatment_ID', 'Treatment', 'Station_ID.y'), as.factor) %>%
  rename(Station_ID = Station_ID.y)


```

## Compare means and medians of Sphagnum cover

```{r}
reveg_var %>%
  group_by(Station_ID, t_year) %>%
  filter(Treatment == 'S') %>%
  summarise(
    mean = mean(Sphagnum, na.rm = TRUE),
    se = sd(Sphagnum, na.rm = TRUE) / sqrt(n()),
    sd = sd(Sphagnum, na.rm = TRUE),
    median = median(Sphagnum, na.rm = TRUE),
    Q1 = quantile(Sphagnum, 0.25, na.rm = TRUE),  # First quartile
    Q3 = quantile(Sphagnum, 0.75, na.rm = TRUE)   # Third quartile
  )

```

```{r}
summary_data <- reveg_var %>%
  group_by(Treatment, t_year) %>%
  summarise(
    mean = mean(Sphagnum, na.rm = TRUE),
    sd = sd(Sphagnum, na.rm = TRUE),
    se = sd(Sphagnum, na.rm = TRUE) / sqrt(n()),
    median = median(Sphagnum, na.rm = TRUE),
    Q1 = quantile(Sphagnum, 0.25, na.rm = TRUE),  # First quartile
    Q3 = quantile(Sphagnum, 0.75, na.rm = TRUE)   # Third quartile
  )

summary_data
```

```{r}

# Plot individual points, mean, median, SE, and quartiles
median_plot <- ggplot(reveg_var, aes(x = t_year)) +
  geom_point(aes(y = Sphagnum, color = Treatment), position = position_jitter(width = 0.2), alpha = 0.5) +  # Points for individual data
  geom_errorbar(data = summary_data, aes(x = t_year, ymin = mean - se, ymax = mean + se), width = 0.2, color = "blue") +  # SE error bars
  geom_errorbar(data = summary_data, aes(x = t_year, ymin = mean - sd, ymax = mean + sd), width = 0.2, color = "orange") +  # SE error bars
  geom_point(data = summary_data, aes(x = t_year, y = mean), color = "blue", size = 3, shape = 21, fill = "blue") +  # Mean points
  geom_point(data = summary_data, aes(x = t_year, y = median), color = "red", size = 3, shape = 21, fill = "red") +  # Median points
  geom_errorbar(data = summary_data, aes(x = t_year, ymin = Q1, ymax = Q3), width = 0.2, color = "red") +  # Quartile range
  labs(x = "Year", y = "Sphagnum cover", title = "Sphagnum Cover over Time with Mean, Median, SE, and Quartiles") +
  facet_wrap(~Treatment) +  # Facet by Treatment, displaying side by side
  theme_minimal()

#ggsave(filename = '../figures/meansmedian.png', plot = median_plot)
median_plot
```

When comparing means with medians, the means mostly lies slightly higher than the medians, with much narrower SE than the quartiles, with the exception of S and R year3, where the median is higher than the mean.

```{r}
reveg_var %>%
  group_by(Location, t_year, Treatment) %>%
  summarise(mean = mean(Sphagnum, na.rm = TRUE),
    se = sd(Sphagnum, na.rm = TRUE) / sqrt(n()),
    sd = sd(Sphagnum, na.rm = TRUE),
    median = median(Sphagnum, na.rm = TRUE),
    Q1 = quantile(Sphagnum, 0.25, na.rm = TRUE),  # First quartile
    Q3 = quantile(Sphagnum, 0.75, na.rm = TRUE)   # Third quartile
  )
```

```{r}
reveg_var %>%
  group_by(Location, Sublocation, t_year, Treatment) %>%
  summarise(mean = mean(Sphagnum, na.rm = TRUE),
    se = sd(Sphagnum, na.rm = TRUE) / sqrt(n()),
    sd = sd(Sphagnum, na.rm = TRUE),
    median = median(Sphagnum, na.rm = TRUE),
    Q1 = quantile(Sphagnum, 0.25, na.rm = TRUE),  # First quartile
    Q3 = quantile(Sphagnum, 0.75, na.rm = TRUE)   # Third quartile
  )
```

# Preparing the data

Filter the data down to year 3 only

```{r}
H1.Sph.revWT <- reveg_wt %>%
  filter(t_year==3) %>%
  filter(Treatment!='R') %>%
  select(Location, Sublocation, Block, Treatment, Station_ID, Roughness, Slope, Sphagnum, Change_Total, Sphagnum_nozero, Sphagnum_int, Sphagnum_no1, Sphagnum_beta)

```

```{r}
WT <- reveg_wt %>%
  filter(Treatment != 'R') %>%
  filter(!is.na(Station_ID)) %>%
  select(c(year, Location, Sublocation, Station_ID, t_year, consecutive_days_count, gs_mean, gs_max, gs_min, total_days)) %>%
   distinct(year, Station_ID, .keep_all = TRUE)

WT2 <- WT %>%
  group_by(Location, Sublocation, Station_ID) %>%
 summarise(WT_consecutive_days_below_max = max(consecutive_days_count),
           WT_mean = mean(gs_mean, na.rm = TRUE),
           WT_total_days_below_sum = sum(total_days),
           WT_max = mean(gs_max, na.rm = TRUE),
           WT_min = mean(gs_min, na.rm = TRUE))

WT2
```

```{r}
H1.Sph.revWT <- full_join(H1.Sph.revWT, WT2, by=c('Location', 'Sublocation', 'Station_ID'))
```

```{r}
#Checking for zeros and ones
summary(H1.Sph.revWT$Sphagnum_beta / 100)
# All is good here, no values are 0 and no values are 1

#Check for missing values
summary(H1.Sph.revWT)
colSums(is.na(H1.Sph.revWT))
```

Lacking some data within WT_consecutive_days_below_max and WT_total_days_below_sum for BSM1, and all for HM2.

Also a small error in Station-ID for HM2, which I'll fix quickly.

```{r}
H1.Sph.revWT <- H1.Sph.revWT %>%
  mutate(Station_ID = as.character(Station_ID),               # Convert to character
         Station_ID = ifelse(is.na(Station_ID), "HM2", Station_ID),  # Replace NA with "HM2"
         Station_ID = as.factor(Station_ID)) #convert back to factor
```

## Imputing missing WT values

Then I'll also impute missing values for WT by using the means from nearby stations

```{r}
# Custom function to impute missing values based on nearby stations
impute_custom <- function(data, target_column, target_station, nearby_stations) {
  # Calculate the mean of the nearby stations
  mean_value <- data %>%
    filter(Station_ID %in% nearby_stations) %>%
    summarise(mean_value = mean(!!sym(target_column), na.rm = TRUE)) %>%
    pull(mean_value)
  
  # Impute the missing values in the target station
  data <- data %>%
    mutate(!!sym(target_column) := ifelse(Station_ID == target_station & is.na(!!sym(target_column)), mean_value, !!sym(target_column)))
  
  return(data)
}

# Impute missing values for BSM-1 and HM-2
H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT, 'WT_consecutive_days_below_max', 'BSM1', c('BSM2', 'BSM3'))
H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT.imp, 'WT_consecutive_days_below_max', 'HM2', c('HM1', 'HM3'))

H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT.imp, 'WT_total_days_below_sum', 'BSM1', c('BSM2', 'BSM3'))
H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT.imp, 'WT_total_days_below_sum', 'HM2', c('HM1', 'HM3'))

H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT.imp, 'WT_mean', 'HM2', c('HM1', 'HM3'))
H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT.imp, 'WT_max', 'HM2', c('HM1', 'HM3'))
H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT.imp, 'WT_min', 'HM2', c('HM1', 'HM3'))

colSums(is.na(H1.Sph.revWT.imp))
```

# Run brms models Sphagnum

## brms model H1

```{r}
init_fun <- function() list(
  b = rnorm(1, 0, 1),
  phi = runif(1, 0.1, 1)
)
```

```{r}
H1.Sph.beta.revWT<-   brm(Sphagnum_beta/100 ~ Treatment + WT_total_days_below_sum + WT_consecutive_days_below_max + WT_mean + (1 | Location/Sublocation),
                   data=H1.Sph.revWT.imp,
                 Beta(link = "logit", link_phi = "log"),
                chains = 4, # nb of chains
                 iter = 4000, # nb of iterations, including burnin
                 warmup = 1000, # burnin
                control = list(adapt_delta = 0.99, max_treedepth = 15))
              

#saveRDS(H1.Sph.beta.revWT, 'RDS-files/H1.Sph.beta.revWT.RDS')
#readRDS(H1.Sph.beta.revWT, 'RDS-files/H1.Sph.beta.revWT.RDS')
```

```{r}
summary(H1.Sph.beta.revWT)
```

```{r}
plot(H1.Sph.beta.revWT)

```

```{r}
# Open a PNG device
png("chain_convergence.png", width = 800, height = 600)

# Capture the plots generated by `plot()`
plots <- plot(H1.Sph.beta.revWT)

# Use grid.arrange to arrange the plots
grid.arrange(grobs = plots)

# Close the device
dev.off()
```

```{r}
# Bayesian R-squared
r2 <- bayes_R2(H1.Sph.beta.revWT)
print(r2)
```

```{r}
pp_check(H1.Sph.beta.revWT, ndraws = 100, type = 'dens_overlay')
```

## brms model H3

```{r}
H3.Sph.beta.revWT<-   brm(Sphagnum_beta/100 ~ WT_total_days_below_sum + WT_consecutive_days_below_max + WT_mean + (1 | Location/Sublocation),
                   data=H1.Sph.revWT.imp,
                 Beta(link = "logit", link_phi = "log"),
                chains = 4, # nb of chains
                 iter = 4000, # nb of iterations, including burnin
                 warmup = 1000, # burnin
                control = list(adapt_delta = 0.99, max_treedepth = 15),
                init = init_fun
)
# saveRDS(H3.Sph.beta.revWT.imp, 'RDS-files/H3.Sph.beta.revWT.imp.RDS')
readRDS(H3.Sph.beta.revWT.imp, 'RDS-files/H3.Sph.beta.revWT.imp.RDS')              
```

```{r}
summary(H3.Sph.beta.revWT.imp)
```

```{r}
pp_check(H3.Sph.beta.revWT.imp, ndraws = 100, type = 'dens_overlay')
```

# Compare the models

```{r}
loo_H1 <- loo(H1.Sph.beta.revWT.imp)
loo_H3 <- loo(H3.Sph.beta.revWT.imp)

loo_compare(loo_H1, loo_H3)
```

```{r}
# Create the pp_check plot
ppc_H1 <- pp_check(H1.Sph.beta.revWT, ndraws = 100, type = 'dens_overlay')

# Add axis labels
ppc_H1 <- ppc_H1 + labs(x = "Proportion of Sphagnum cover", y = "Density")

# Save the plot to a file
ggsave(filename = '../figures/ppc_H1.revWT.png', plot = ppc_H1)
ppc_H1
```

## brms model H3 Sphagnum treatment only

Testing the water table variables when only including Sphagnum treatment

```{r}

H3.Sph.beta.revWT_S<-   brm(Sphagnum_beta/100 ~ WT_total_days_below_sum + WT_consecutive_days_below_max + WT_mean + (1 | Location/Sublocation),
                   data=H1.Sph.revWT.imp %>% filter(Treatment=="S"),
                 Beta(link = "logit", link_phi = "log"),
                chains = 4, # nb of chains
                 iter = 4000, # nb of iterations, including burnin
                 warmup = 1000, # burnin
                control = list(adapt_delta = 0.99, max_treedepth = 15))

 saveRDS(H3.Sph.beta.revWT_S, 'RDS-files/H3.Sph.beta.revWT_S.RDS')
readRDS(H3.Sph.beta.revWT_S, 'RDS-files/H3.Sph.beta.revWT_S.RDS')  
```

```{r}
summary(H3.Sph.beta.revWT_S)
```

the WT variables are still not significant when looking at only S treatments. I thought it would be, considering the great difference in the variable values at VSM-1 and the response value compared to the other sublocations.

The model is only using the WT values from year 3, though...

## Create plot of posterior distributions

```{r}
# Extract posterior samples
posterior_samples <- as.data.frame(H1.Sph.beta.revWT.imp)

# List of variables of interest
variables <- c("b_Treatment", "b_WT_consecutive_days_below_max", 
               "b_WT_total_days_below_sum")

# Extracting posterior samples for the variables of interest
selected_columns <- colnames(posterior_samples)[grepl(paste(variables, collapse = "|"), colnames(posterior_samples))]

# Reshape data for ggplot2
posterior_data <- posterior_samples %>%
  pivot_longer(cols = all_of(selected_columns), names_to = "Variable", values_to = "Value")

# Rename variables for better y-axis labels
posterior_data$Variable <- recode(posterior_data$Variable, 
                                  "b_WT_consecutive_days_below_max" = "max consecutive days low WT",
                                  "b_WT_total_days_below_sum" = "total days low WT",
                                  "b_TreatmentS" = "Treatment M&S",
                                  'b_TreatmentM' = 'Treatment M')  

# Define x-axis limits to exclude extreme tails
x_limits <- c(-2.5, 5)  # Adjust these values based on your data

# Create the ridge plot
ridge_plot <- ggplot(posterior_data, aes(x = Value, y = Variable, fill = Variable)) +
  geom_density_ridges() +
  labs(x = "Posterior value", y = "Explanatory variable", title = "Posterior distributions of explanatory variables") +
  theme_ridges() +
  theme(legend.position = "none",
        plot.title = element_text(size = 14, hjust=0, vjust=1),
        axis.title.x = element_text(hjust = 0.5, vjust = 0.5),   # Move x-axis label to the left
    axis.title.y = element_text(margin = margin(t = 80, r = 10, b = 0, l = 0))) + # Move y-axis somewhat down
  coord_cartesian(xlim = x_limits) +
  scale_fill_brewer(palette = "PuOr")


# Save the plot
ggsave(filename = '../figures/treatment_posterior_distributions.H1.revWT.imp.png', plot = ridge_plot)
ridge_plot
```

Running any interaction models are definitely too complex for the data (I've tested, with models not converging and lots of warnings).

# New model with WT as random variable

As WT isn't coming through as significant, although I think it should, I'm starting to think the structure of the models are wrong.

I truly only want to test Sphagnum cover over treatment, that is the experiment. WT is only something that is controlled for, as hydrology is always considered an important factor for Sphagnum development.

The problem is the inclusion of the nested structure, it might actually "soak up" all the variation between Location/Sublocation, and all variation within WT would be on a Sublocation-level. I think that I either need to drop another level of the nesting-structure or I would need to include WT as a random variable.

I got a suggestion of including it as a random slope. The structure of the random variable would then be e.g. WT_mean\|Location/Sublocation or WT_mean\|Location. I'm not sure if I should include Sublocation then.

```{r}
mod3 <- brm(Sphagnum_beta / 100 ~ Treatment + (WT_mean | Location/Sublocation),
    data = H1.Sph.revWT.imp,
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    save_pars = save_pars(all = TRUE))

saveRDS(mod3, 'RDS-files/mod3_Sph_WTrev_WTrandom.RDS')
#readRDS(mod3, 'RDS-files/mod3_Sph_WTrev_WTrandom.RDS')  
```

```{r}
summary(mod3)
```

Testing then without Treatment, on only S data...

```{r}
mod4 <- brm(Sphagnum_beta / 100 ~ 1 + (WT_mean | Location/Sublocation),
    data = H1.Sph.revWT.imp %>% filter(Treatment=="S"),
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15))

saveRDS(mod4, 'RDS-files/mod4_WTrev_WTrandom.RDS')
```

```{r}
summary(mod4)
```

This looks more or less similar to the previous model (mod3), indicating that the random slope and intercept doesn't change with adding a fixed effect.

```{r}
mod5 <- brm(Sphagnum_beta / 100 ~ 1 + (WT_mean | Location/Sublocation),
    data = H1.Sph.revWT.imp,
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15),
    save_pars = save_pars(all = TRUE))

#saveRDS(mod5, 'RDS-files/mod5_WTrev_WTrandom.RDS')
#readRDS(mod5, 'RDS-files/mod5_WTrev_WTrandom.RDS')  
```

```{r}
summary(mod5)
```

```{r}
mod6 <- brm(Sphagnum_beta / 100 ~ WT_mean +(1 | Location/Sublocation),
    data = H1.Sph.revWT.imp %>% filter(Treatment=="S"),
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15))

saveRDS(mod6, 'RDS-files/mod6_WTrev_S_WTmean.RDS')
```

```{r}
summary(mod6)
```

```{r}
mod8 <- brm(Sphagnum_beta / 100 ~ Treatment + (1|WT_mean) +(1 | Location/Sublocation),
    data = H1.Sph.revWT.imp,
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15))

saveRDS(mod8, 'RDS-files/mod8_WTrev_S_WTrandom.RDS')
```

```{r}
summary(mod8)
```

```{r}
mod9 <- brm(Sphagnum_beta / 100 ~ 1 + (1|WT_mean) +(1 | Location/Sublocation),
    data = H1.Sph.revWT.imp,
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15))

saveRDS(mod9, 'RDS-files/mod9_WTrev_WTrandom.RDS')
```

```{r}
summary(mod9)
```

## Compare the models (mod3 and mod5, mod8 and mod9)

```{r}
loo_mod3 <- loo(mod3)
loo_mod5 <- loo(mod5)

loo_compare(loo_mod3, loo_mod5)
```

```         
Warning: Found 1 observations with a pareto_k > 0.7 in model 'mod3'. We recommend to set 'moment_match = TRUE' in order to perform moment matching for problematic observations.
```

```{r}
loo_mod8 <- loo(mod8)
loo_mod9 <- loo(mod9)

loo_compare(loo_mod8, loo_mod9)
```

```{r}
loo_compare(loo_mod3, loo_mod5, loo_mod8, loo_mod9)
```

Checking with Bayesian R-squared to compare variance.

```{r}
# Calculate Bayesian R-squared for both models
bayes_R2_mod3 <- bayes_R2(mod3)
bayes_R2_mod5 <- bayes_R2(mod5)
bayes_R2_mod8 <- bayes_R2(mod8)
bayes_R2_mod9 <- bayes_R2(mod9)

print(bayes_R2_mod3)
print(bayes_R2_mod5)
print(bayes_R2_mod8)
print(bayes_R2_mod9)
```

```{r}
bayes_factor(mod3, mod5)
```

Bayes Factor seems very unstable, with extreme values, so I'm going to keep up with LOOCV.

```{r}
plot(mod8)
```

```{r}
# Create the MCMC plot
mcmc_plot_mod8 <- mcmc_plot(mod8)

# Save the plot as a PNG file
ggsave(filename = '../figures/mcmc_plot_mod8.png', plot = mcmc_plot_mod8)

mcmc_plot_mod8
```

```{r}
#Create a trace plot with the main parameters

parameters <- tidybayes::get_variables(mod8)
print(parameters)

#I want to include: "b_Intercept", "b_TreatmentS", "b_TreatmentM", "sd_Location__Intercept"  , "sd_WT_mean__Intercept", "sd_Location:Sublocation__Intercept", "phi"

# Create the trace plot for specific main parameters
trace_plot_mod8<- mcmc_trace(mod8, pars = c("b_Intercept", "b_TreatmentS", "b_TreatmentM", "sd_WT_mean__Intercept", "sd_Location__Intercept"  ,  "sd_Location:Sublocation__Intercept", "phi"))  # Example parameters


ggsave(filename = '../figures/trace_plot_mod8.png', plot=trace_plot_mod8)
trace_plot_mod8
```

```{r}
# Create the pp_check plot
ppc_mod8 <- pp_check(mod8, ndraws = 100, type = 'dens_overlay')

# Add axis labels
ppc_mod8 <- ppc_mod8 + labs(x = "Proportion of Sphagnum cover", y = "Density")

# Save the plot to a file
ggsave(filename = '../figures/ppc_mod8.png', plot = ppc_mod8)
ppc_mod8
```

```{r}
# Create the pp_check plot
ppc_mod5 <- pp_check(mod5, ndraws = 100, type = 'dens_overlay')

# Add axis labels
ppc_mod5 <- ppc_mod5 + labs(x = "Proportion of Sphagnum cover", y = "Density")

# Save the plot to a file
ggsave(filename = '../figures/ppc_mod5.png', plot = ppc_mod5)
ppc_mod5
```

## Create plot of posterior distributions

```{r}
# Extract posterior samples
posterior_samples <- as.data.frame(mod8)

# List of variables of interest
variables <- c("b_Intercept", "b_TreatmentS", "b_TreatmentM", "sd_WT_mean__Intercept", "sd_Location__Intercept"  , "sd_Location:Sublocation__Intercept", "phi")

# Extracting posterior samples for the variables of interest
selected_columns <- colnames(posterior_samples)[grepl(paste(variables, collapse = "|"), colnames(posterior_samples))]

# Reshape data for ggplot2
posterior_data <- posterior_samples %>%
  pivot_longer(cols = all_of(selected_columns), names_to = "Variable", values_to = "Value")

# Rename variables for better y-axis labels
posterior_data$Variable <- recode(posterior_data$Variable, 
                                  "b_Intercept" = "Intercept of control",
                                  "b_TreatmentS" = "Sphagnum treatment",
                                  'b_TreatmentM' = 'Mulch treatment',
                                  "sd_Location__Intercept" = "Intercept of sd within locations",
                                  "sd_Location:Sublocation__Intercept" = "Intercept of sd within sublocations",
                                  "sd_WT_mean__Intercept" = "Intercept of sd mean water table"
                                  )  

# Define x-axis limits to exclude extreme tails
x_limits <- c(-5, 5)  # Adjust these values based on your data

# Create the ridge plot
ridge_plot <- ggplot(posterior_data, aes(x = Value, y = Variable, fill = Variable)) +
  geom_density_ridges() +
  labs(x = "Posterior value", y = "Explanatory variable", title = "Posterior distributions of explanatory variables") +
  theme_ridges() +
  theme(legend.position = "none",
        plot.title = element_text(size = 14, hjust=0, vjust=1),
        axis.title.x = element_text(hjust = 0.5, vjust = 0.5),   # Move x-axis label to the left
    axis.title.y = element_text(margin = margin(t = 80, r = 10, b = 0, l = 0))) + # Move y-axis somewhat down
  coord_cartesian(xlim = x_limits) +
  scale_fill_brewer(palette = "PuOr")


# Save the plot
ggsave(filename = '../figures/treatment_posterior_distributions.mod8.png', plot = ridge_plot)
ridge_plot
```

Then a figure with only the explanatory variable

```{r}
# List of variables of interest
variables <- c("b_Intercept", "b_TreatmentS", "b_TreatmentM")

# Extracting posterior samples for the variables of interest
selected_columns <- colnames(posterior_samples)[grepl(paste(variables, collapse = "|"), colnames(posterior_samples))]

# Reshape data for ggplot2
posterior_data <- posterior_samples %>%
  pivot_longer(cols = all_of(selected_columns), names_to = "Variable", values_to = "Value")

# Rename variables for better y-axis labels
posterior_data$Variable <- recode(posterior_data$Variable, 
                                  "b_Intercept" = "Intercept of Control",
                                  "b_TreatmentS" = "Sphagnum treatment",
                                  'b_TreatmentM' = 'Mulch treatment')  

# Define x-axis limits to exclude extreme tails
x_limits <- c(-5, 5)  # Adjust these values based on your data

# Create the ridge plot
ridge_plot2 <- ggplot(posterior_data, aes(x = Value, y = Variable, fill = Variable)) +
  geom_density_ridges() +
  labs(x = "Posterior value", y = "Explanatory variable", title = "Posterior distributions of explanatory variables") +
  theme_ridges() +
  theme(legend.position = "none",
        plot.title = element_text(size = 14, hjust=0, vjust=1),
        axis.title.x = element_text(hjust = 0.5, vjust = 0.5),   # Move x-axis label to the left
    axis.title.y = element_text(margin = margin(t = 80, r = 10, b = 0, l = 0))) + # Move y-axis somewhat down
  coord_cartesian(xlim = x_limits) +
  scale_fill_brewer(palette = "PuOr")


# Save the plot
ggsave(filename = '../figures/treatment_posterior_distributions.mod8_exp.png', plot = ridge_plot2)

ridge_plot2
```

The negative values of the Intercept (control group) indicate a proportion \< 0.5.

```{r}
# Generate predictions for the control group 
# Filter out "R" and drop unused factor levels
H1.Sph.revWT.imp <- H1.Sph.revWT.imp %>%
  filter(Treatment != "R") %>%
  droplevels()  # This removes "R" from the factor levels

control_preds <- H1.Sph.revWT.imp %>%
  filter(Treatment == "C") %>%
  add_epred_draws(mod3)

# Calculate the mean of the predicted values for the control group
mean_control_pred <- mean(control_preds$.epred)
mean_control_pred
```

```{r}
reveg_var %>%
  group_by(Treatment, t_year) %>%
  summarise(
   max = max(Sphagnum, na.rm=TRUE))

```

# New models with WT as explanatory variable (again)

```{r}
mod10 <- brm(Sphagnum_beta / 100 ~ Treatment + WT_mean +(1 | Location/Sublocation),
    data = H1.Sph.revWT.imp,
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15))

saveRDS(mod10, 'RDS-files/mod10.RDS')
```

```{r}
summary(mod10)
```

```{r}
mod11 <- brm(Sphagnum_beta / 100 ~ WT_mean +(1 | Location/Sublocation),
    data = H1.Sph.revWT.imp,
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15))

saveRDS(mod11, 'RDS-files/mod11.RDS')
```

```{r}
summary(mod11)
```

```{r}
bayes_R2_mod10 <- bayes_R2(mod10)
bayes_R2_mod11 <- bayes_R2(mod11)

print(bayes_R2_mod10)
print(bayes_R2_mod11)
```

```{r}

loo_mod10 <- loo(mod10)
loo_mod11 <- loo(mod11)

loo_compare(loo_mod8, loo_mod9, loo_mod10, loo_mod11)
```

```{r}
mod11 <- brm(Sphagnum_beta / 100 ~ WT_mean +(1 | Location/Sublocation),
    data = H1.Sph.revWT.imp,
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15))

saveRDS(mod11, 'RDS-files/mod11.RDS')
```

```{r}
mod12 <- brm(Sphagnum_beta / 100 ~ Treatment + WT_mean + WT_min + (1 | Location/Sublocation),
    data = H1.Sph.revWT.imp,
    family = Beta(link = "logit", link_phi = "log"), 
    chains = 4, 
    iter = 4000, 
    warmup = 1000, 
    control = list(adapt_delta = 0.99, max_treedepth = 15))

saveRDS(mod12, 'RDS-files/mod12.RDS')
```

```{r}
summary(mod12)
```

```{r}
bayes_R2_mod12 <- bayes_R2(mod12)
print(bayes_R2_mod12)
```

```{r}
mod11 <- readRDS(file = "RDS-files/mod11.RDS")
```

```{r}
summary(mod11)
```

```{r}
mod10 <- readRDS(file = "RDS-files/mod10.RDS")
```

```{r}
summary(mod10)
```
