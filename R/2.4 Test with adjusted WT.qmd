---
title: "Updates with corrected WT at BSM"
author: "MarteF"
format: html
editor: visual
---

## Packages needed

```{r}
library(readr)
library(lubridate)
library(scales)
library(gridExtra)
library(timetk)
library(brms) # bayesian approach to glmm, but with easier steps 
library(posterior) # tools for working with posterior and prior distributions 
library(lme4) # fit GLMM in frequentist framework 
library(tidyverse) # everything for data wrangling (included ggplot2)
library(dplyr) # some more for data wrangling 
library(rstan) 
library(bayesplot) 
library(loo)  
library(sjPlot)
library(insight)
library(ggridges)
library(ggrepel)

options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
```

# WT adjustments and rerunning of code to create WT variables

```{r}
wt_all <- readr::read_delim('../data/wt_all.csv', 
                                  delim = ',',
                                  col_names = TRUE)

#Filter data for growth season
wt_season <- wt_all %>%     
  filter((year >= 2020 & year < 2023) & (month >= 5 & month <= 9) | (year == 2023) & (month >= 5 & month<9))

#Create julian date column
wt_season$jday <- yday(wt_season$Date)
wt_season$month_name <- format(wt_season$Date,"%B")
wt_season$month_name <- factor(wt_season$month_name, levels = month.name)

#Filter out the malfunctioning stations
wt_season <- wt_season %>%
  filter(!(year %in%  c('2022', '2023') & Station_ID=='BSM1')) %>%
  filter(Station_ID!='HM2')
```

## Adjust the values of BSM1, BSM2, BSM3

```{r}
#Checking max level
wt_season %>%
  filter(Station_ID=='BSM1') %>%
        summarise(max=max(LEVEL))

# I don't have realtime data for this station, as it was malfunctioning in 2022 (when I did realtime measurements)

# Filter data for the desired Station_IDs
adjusted_data_BSM1 <- wt_season%>%
  filter(Station_ID %in% c("BSM1")) %>%
  group_by(Station_ID) %>%
  mutate(LEVEL = LEVEL - max(LEVEL)) %>%
  ungroup()

# View the adjusted data
print(adjusted_data_BSM1)
```

```{r}
wt_season %>%
  filter(Station_ID %in% c('BSM1')) %>%
  group_by(Station_ID)
```

```{r}

#Checking max level
wt_season %>%
  filter(Station_ID=='BSM2') %>%
        summarise(max=max(LEVEL))

#Checking levels at 22/6-22, when I have realtime data
wt_season %>%
  filter(Station_ID=='BSM2', Date == as.Date("2022-06-22"))

# Filter data for the desired Station_IDs         
adjusted_data_BSM2 <- wt_season%>%
  filter(Station_ID %in% c("BSM2")) %>%
  group_by(Station_ID) %>%
  mutate(LEVEL = LEVEL - max(LEVEL)) %>%
  ungroup()

# View the adjusted data
print(adjusted_data_BSM2)
```

```{r}
wt_season %>%
  filter(Station_ID %in% c('BSM2')) %>%
  group_by(Station_ID)
```

```{r}
#Checking max level
wt_season %>%
  filter(Station_ID=='BSM3') %>%
        summarise(max=max(LEVEL))

#Checking levels at 22/6-22, when I have realtime data
wt_season %>%
  filter(Station_ID=='BSM3', Date == as.Date("2022-06-22"))

# Filter data for the desired Station_IDs         
adjusted_data_BSM3 <- wt_season%>%
  filter(Station_ID %in% c("BSM3")) %>%
  group_by(Station_ID) %>%
  mutate(LEVEL = LEVEL - max(LEVEL)) %>%
  ungroup()

# View the adjusted data
print(adjusted_data_BSM3)
```

```{r}
wt_season %>%
  filter(Station_ID %in% c('BSM3')) %>%
  group_by(Station_ID)
```

```{r}
# Combine adjusted data with the rest of the dataset
combined_data <- wt_season %>%
  filter(!Station_ID %in% c("BSM1", "BSM2", "BSM3")) %>%
  bind_rows(adjusted_data_BSM1, adjusted_data_BSM2, adjusted_data_BSM3)
```

## Create new variables

```{r}
#Daily means of WT values
daily_means <- combined_data %>%
  mutate(Location = case_when(
    grepl("^BSM", Station_ID) ~ "BSM",
    grepl("^VSM", Station_ID) ~ "VSM",
    grepl("^HM", Station_ID) ~ "HM",
    TRUE ~ NA_character_  # This handles any cases not matching the specified pattern
  )) %>%
  group_by(Station_ID, Location, jday, month_name, year) %>%
 summarise_by_time(.date_var=DateTime,
                    .by="day",
                    daily_mean = mean(LEVEL), daily_max = max(LEVEL), daily_min= min(LEVEL))

daily_means
```

```{r}
#Summary per growth season
gs <-combined_data%>%
  group_by(Station_ID, year)%>%
  summarise_by_time(.date_var=DateTime,
                    .by="year", gs_mean = mean(LEVEL), gs_max = max(LEVEL), gs_min = min(LEVEL) )
gs
```

```{r}
# Create variable for days below -20cm WT within growth season
daily_means <- daily_means %>%
  mutate(year=as.factor(year(DateTime))) %>%
  mutate(month=as.factor(month(DateTime)))

total_days_below_minus_0.2 <- daily_means %>% 
  filter(daily_mean < -0.2) %>% 
  group_by(Station_ID, year) %>% 
  summarise(total_days = n_distinct(DateTime))%>%
  ungroup()%>%
 complete(Station_ID, year, fill = list(total_days = 0)) %>%
ungroup()
print(total_days_below_minus_0.2, n = Inf)

# Create a data frame with all combinations of year, month, and Station_ID
all_combinations <- expand.grid(
  year = unique(daily_means$year),
  Station_ID = unique(daily_means$Station_ID)
)

# Join the data frame with all combinations with the calculated data
total_days_below_minus_0.2_complete <- left_join(all_combinations, total_days_below_minus_0.2, by = c("year", "Station_ID"))
total_days_below_minus_0.2_complete$total_days[is.na(total_days_below_minus_0.2_complete$total_days)] <- 0

#This is not perfect, as it creates zeros for years that were not measured. BSM was not measured in 2020.

total_days_below_minus_0.2_complete <- total_days_below_minus_0.2_complete %>%
   filter(!(Station_ID %in% c("BSM1", "BSM2", "BSM3") & year == '2020'))

total_days_below_minus_0.2_complete
```

```{r}
#Create variable for max no of consecutive days wit WT <-0.2 within growth season
df <- daily_means %>%
  mutate(consecutive_days = daily_mean < -0.2) %>%
  group_by(Station_ID, year) %>%
  mutate(consecutive_days = cumsum(consecutive_days) - cummax((!consecutive_days) * cumsum(consecutive_days))) %>%
  ungroup()

result <- df %>%
  group_by(Station_ID, year) %>%
  summarise(consecutive_days_count = max(consecutive_days)) %>%
  ungroup()

result
```

```{r}
#Combine variables for growth season
gs <- gs %>% 
  select(-c('DateTime')) %>%
  mutate(year=as.factor(year))


final_variables <- result %>%
  full_join(gs, by=c('Station_ID','year'))
final_variables <- final_variables %>%
  full_join(total_days_below_minus_0.2_complete, by=c('Station_ID', 'year'))

final_variables %>%
  rename(consecutive_days_low_gs = consecutive_days_count, total_days_low_gs = total_days)

#write.csv(final_variables, '../data/WT_variables2.csv')
#final_variables <- readr::read_delim('../data/WT_variables2.csv',
 #                      delim =  ',',
  #                    col_names = TRUE)
final_variables
```

```{r}
final_variables_loc <- final_variables %>%
mutate(Location = case_when(
    grepl("^BSM", Station_ID) ~ "BSM",
    grepl("^VSM", Station_ID) ~ "VSM",
    grepl("^HM", Station_ID) ~ "HM",
    TRUE ~ NA_character_  # This handles any cases not matching the specified patterns
  )) %>%
  group_by(Location, year) %>%
  summarise(max_WT_below_cons = max(consecutive_days_count, na.rm=TRUE),
            WT_mean = mean(gs_mean, na.rm = TRUE),
            WT_max = max(gs_max, na.rm = TRUE),
            WT_min = min(gs_min, na.rm = TRUE),
            total_days_below = max(total_days, na.rm=TRUE))
final_variables_loc
```

```{r}
gs_loc <- wt_season %>%
  mutate(Location = case_when(
    grepl("^BSM", Station_ID) ~ "BSM",
    grepl("^VSM", Station_ID) ~ "VSM",
    grepl("^HM", Station_ID) ~ "HM",
    TRUE ~ NA_character_ )) %>% # This handles any cases not matching the specified patterns 
  group_by(Location, year)%>%
  summarise_by_time(.date_var=DateTime, .by="year", gs_mean = mean(LEVEL), gs_max = max(LEVEL), gs_min = min(LEVEL))
  
gs_loc
```

## Combine WT with precipitation

```{r}
climdat_season <- readr::read_delim('../data/climdat_season.csv',
                       delim =  ',',
                      col_names = TRUE)

#rename columns in climdat_season
climdat_season <- climdat_season %>%
  rename(clim_station = Name, Date = Time) %>%
  mutate(across(c('year', 'month'), as.factor))

#Create column for the weather station in the daily_means dataset
daily_means <- daily_means %>%
  mutate(clim_station = case_when(Location== 'VSM' ~ 'Vestersetermyra',
                         Location=='HM' ~ 'Hoydalsmoan',
                         Location == 'BSM' ~ 'Hoydalsmoan',
                                TRUE ~ NA))

#rename columns in daily_means
daily_means <- daily_means %>%
  rename(Date=DateTime)

#join climate and WT
clim_wt <- daily_means %>%
  left_join(climdat_season, by=c('clim_station', 'Date', 'year', 'month', 'jday', 'month_name'))

clim_wt_combined <- clim_wt %>%
  group_by(Station_ID, Location, clim_station, Date, jday, month_name, year, Year, month, Month) %>%
  summarize(
    WT_daily_mean = mean(daily_mean, na.rm = TRUE),
    WT_daily_max = mean(daily_max, na.rm = TRUE),
    WT_daily_min = mean(daily_min, na.rm = TRUE),
    max_temp = first(Max_temp),  # Adjust this function based on your needs
    mean_temp = first(Mean_temp),
    min_temp = first(Min_temp),
    prec = last(Precipitation))

rm(clim_wt)

#write.csv(clim_wt_combined, file = '../data/clim_wt_combined2.csv')
clim_wt_combined
```

```{r}
plot_BSM2 <- clim_wt_combined %>%
  filter(Station_ID == "BSM2", Date >= as.Date("2021-05-15") & Date <= as.Date("2021-09-15")) %>%
  ggplot(aes(x = Date)) +
  # WT_daily_mean as blue bars going downward from 0
  geom_line(aes(y = WT_daily_mean), color= "darkblue", size= 1) +
  # prec as red bars going upward from 0
  geom_bar(aes(y = prec / 30 * 0.50), stat = "identity", fill = "lightblue", color= "darkblue", alpha = 0.7) +
  scale_y_continuous(
    name = "WT_daily_mean",
    limits = c(-0.50, 0.50),
    sec.axis = sec_axis(~ . * 60, name = "prec", breaks = seq(-30, 30, 10))
  ) +
  labs(title = "WT_daily_mean and Precipitation per Day (15.06.2021 to 15.08.2021) for Station_ID BSM2",
       x = "Date", y = "WT_daily_mean") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

plot_BSM2

```

```{r}
plot_BSM1 <- clim_wt_combined %>%
  filter(Station_ID == "BSM1", Date >= as.Date("2021-05-15") & Date <= as.Date("2021-09-15")) %>%
  ggplot(aes(x = Date)) +
  # WT_daily_mean as blue bars going downward from 0
  geom_line(aes(y = WT_daily_mean), color= "darkblue", size= 1) +
  # prec as red bars going upward from 0
  geom_bar(aes(y = prec / 30 * 0.50), stat = "identity", fill = "lightblue", color= "darkblue", alpha = 0.7) +
  scale_y_continuous(
    name = "WT_daily_mean",
    limits = c(-0.50, 0.50),
    sec.axis = sec_axis(~ . * 60, name = "prec", breaks = seq(-30, 30, 10))
  ) +
  labs(title = "WT_daily_mean and Precipitation per Day (15.06.2021 to 15.08.2021) for Station_ID BSM1",
       x = "Date", y = "WT_daily_mean") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

plot_BSM1
```

```{r}
plot_BSM3 <- clim_wt_combined %>%
  filter(Station_ID == "BSM3", Date >= as.Date("2021-05-15") & Date <= as.Date("2021-09-15")) %>%
  ggplot(aes(x = Date)) +
  # WT_daily_mean as blue bars going downward from 0
  geom_line(aes(y = WT_daily_mean), color= "darkblue", size= 1) +
  # prec as red bars going upward from 0
  geom_bar(aes(y = prec / 30 * 0.50), stat = "identity", fill = "lightblue", color= "darkblue", alpha = 0.7) +
  scale_y_continuous(
    name = "Mean WT (m)",
    limits = c(-0.60, 0.60),
       breaks = seq(-0.60, 0.60, by = 0.15),
    sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(-30, 30, 10))
  ) +
  labs(title = "Mean WT and precipitation per day growth season 2021 for BSM3",
       x = "Date", y = "Mean WT") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

plot_BSM3
```

## Reprint all WT and prec figures

```{r}

# # Ensure your data frame is named clim_wt_combined
# # Filter the data for the desired time period
# filtered_data <- clim_wt_combined %>%
#   filter(Date >= as.Date("2020-05-01") & Date <= as.Date("2020-09-30"))
# 
# # Get unique Station_IDs
# unique_stations <- unique(filtered_data$Station_ID)
# 
# # Create a separate figure for each Station_ID
# for (station in unique_stations) {
#   station_data <- filtered_data %>%
#     filter(Station_ID == station)
#   
#   station_comb_plot <- ggplot(station_data, aes(x = Date)) +
#     # WT_daily_mean as blue line underneath surface at 0m
#     geom_line(aes(y = WT_daily_mean), color= "darkblue", size= 1) +
#     # prec as bars going upward from 0
#     geom_bar(aes(y = prec / 30 * 0.60), stat = "identity", fill = "lightblue", color = "darkblue", alpha = 0.7) +
#     scale_y_continuous(
#       name = "Mean WT (m)",
#       limits = c(-0.60, 0.60),
#        breaks = seq(-0.60, 0.60, by = 0.15),
#       sec.axis = sec_axis(~ . * 60, name = "Precipitation (mm)", breaks = seq(-30, 30, 10))
#     ) +
#     labs(title = paste("Mean WT and precipitation per day during growth season 2020 for", station),
#          x = "Date", y = "Mean WT") +
#     theme_minimal() +
#     theme(axis.text.x = element_text(angle = 45, hjust = 1))
#   
#   # Save the plot as a PNG file
#   ggsave(filename = paste0("../figures/WT_prec_2020", station, ".png"), plot = station_comb_plot, width = 10, height = 6)
#   
#   print(station_comb_plot)
# }
```

## Combine WT variables with reveg

```{r}
wtvar <- final_variables 
wtvar <- wtvar %>%  
     mutate(Name=case_when(Station_ID=='BSM1'~ 'Hoydalsmoan', 
                           Station_ID=='BSM2'~'Hoydalsmoan',
                           Station_ID=='BSM3'~'Hoydalsmoan', 
                           Station_ID=='HM1'~'Hoydalsmoan', 
                           Station_ID=='HM2'~'Hoydalsmoan', 
                           Station_ID=='HM3'~'Hoydalsmoan', 
                           Station_ID=='VSM1'~'Vestersetermyra', 
                           Station_ID=='VSM2'~'Vestersetermyra', 
                           TRUE ~ NA)) %>% 
  mutate_at(c('year', 'Station_ID'), as.factor) 

#Created a column for weather station Name in the water table dataset


wtvar <- wtvar%>% 
   relocate(Name) 

# The total days with water table < -0.2m (total_days) are set to zero for those stations that didn't have any data (BSM1 in 2022, 2023, and HM2 in 2021, 2022, 2023). I need to change these to NAs 

wtvar <- wtvar %>% 
  mutate(total_days = case_when( 
         is.na(consecutive_days_count) ~ NA_real_, 
              TRUE ~ total_days 
            )) 
 
#Create similar columns as in reveg dataset 
wtvar <- wtvar %>% 
     separate('Station_ID', into = c('Location', 'Sublocation'), sep = "(?<=\\D)(?=\\d)|(?<=\\d)(?=\\D)", remove = FALSE)

```

```{r}
reveg_var <- readr::read_delim('../data/reveg_var.csv', 
                                  delim = ',',
                                  col_names = TRUE)

reveg_wt <- reveg_var %>%
  select(c(Date:Other, Change_Year:Sphagnum_beta)) %>%
  mutate_at(c('Location','Sublocation', 'Treatment_ID', 'Treatment', 'year', 'Block' ), as.factor)

#Join the revegetation dataset with the variable datasets

reveg_wt <- wtvar %>%
   left_join(reveg_wt, by=c('Location', 'Sublocation', 'year'))

reveg_wt <- reveg_wt %>%
   mutate_at(c('Location','Sublocation', 'Treatment_ID', 'Treatment', 'Station_ID.y'), as.factor) %>%
  rename(Station_ID = Station_ID.y)


```

```{r}
reveg_var %>%
  group_by(Station_ID, t_year) %>%
  filter(Treatment=='S') %>%
  summarise(mean = mean(Sphagnum, na.rm=TRUE),
            se = sd(Sphagnum, na.rm= TRUE/ sqrt(n())))
```

```{r}
reveg_var %>%
  group_by(Location, t_year, Treatment) %>%
  filter(Treatment==(c('S', 'R'))) %>%
  summarise(mean = mean(Sphagnum, na.rm=TRUE),
            se = sd(Sphagnum, na.rm= TRUE/ sqrt(n())))
```

# Run brms models Sphagnum

Year 3 only

```{r}
H1.Sph.revWT <- reveg_wt %>%
  filter(t_year==3) %>%
  filter(Treatment!='R') %>%
  select(Location, Sublocation, Block, Treatment, Station_ID, Roughness, Slope, Sphagnum, Change_Total, Sphagnum_nozero, Sphagnum_int, Sphagnum_no1, Sphagnum_beta)

```

```{r}
WT <- reveg_wt %>%
  filter(Treatment != 'R') %>%
  filter(!is.na(Station_ID)) %>%
  select(c(year, Location, Sublocation, Station_ID, t_year, consecutive_days_count, gs_mean, gs_max, gs_min, total_days)) %>%
   distinct(year, Station_ID, .keep_all = TRUE)

WT2 <- WT %>%
  group_by(Location, Sublocation, Station_ID) %>%
 summarise(WT_consecutive_days_below_max = max(consecutive_days_count),
           WT_mean = mean(gs_mean, na.rm = TRUE),
           WT_total_days_below_sum = sum(total_days))

WT2
```

```{r}
H1.Sph.revWT <- full_join(H1.Sph.revWT, WT2, by=c('Location', 'Sublocation', 'Station_ID'))
rm(WT, WT2)

H1.Sph.revWT <- H1.Sph.revWT %>%
  mutate_at(c('Location', 'Sublocation','Block', 'Treatment'), as.factor)
```

```{r}
#Checking for zeros and ones
summary(H1.Sph.revWT$Sphagnum_beta / 100)
# All is good here, no values are 0 and no values are 1

#Check for missing values
summary(H1.Sph.revWT)
sum(is.na(H1.Sph.revWT))
colSums(is.na(H1.Sph.revWT))
```

```{r}
# Custom function to impute missing values based on nearby stations
impute_custom <- function(data, target_column, target_station, nearby_stations) {
  # Calculate the mean of the nearby stations
  mean_value <- data %>%
    filter(Station_ID %in% nearby_stations) %>%
    summarise(mean_value = mean(!!sym(target_column), na.rm = TRUE)) %>%
    pull(mean_value)
  
  # Impute the missing values in the target station
  data <- data %>%
    mutate(!!sym(target_column) := ifelse(Station_ID == target_station & is.na(!!sym(target_column)), mean_value, !!sym(target_column)))
  
  return(data)
}

# Impute missing values for BSM-1 and HM-2
H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT, 'WT_consecutive_days_below_max', 'BSM-1', c('BSM-2', 'BSM-3'))
H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT.imp, 'WT_consecutive_days_below_max', 'HM-2', c('HM-1', 'HM-3'))

H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT.imp, 'WT_total_days_below_sum', 'BSM-1', c('BSM-2', 'BSM-3'))
H1.Sph.revWT.imp <- impute_custom(H1.Sph.revWT.imp, 'WT_total_days_below_sum', 'HM-2', c('HM-1', 'HM-3'))

colSums(is.na(H1.Sph.revWT.imp))
```

```{r}
init_fun <- function() list(
  b = rnorm(1, 0, 1),
  phi = runif(1, 0.1, 1)
)
```

```{r}
# H1.Sph.beta.revWT<-   brm(Sphagnum_beta/100 ~ Treatment + WT_total_days_below_sum + WT_consecutive_days_below_max + WT_mean + (1 | Location/Sublocation),
#                    data=H1.Sph.revWT,
#                  Beta(link = "logit", link_phi = "log"),
#                 chains = 4, # nb of chains
#                  iter = 4000, # nb of iterations, including burnin
#                  warmup = 1000, # burnin
#                  thin = 3,
#                 control = list(adapt_delta = 0.99, max_treedepth = 15))
              

#saveRDS(H1.Sph.beta.revWT, 'RDS-files/H1.Sph.beta.revWT.RDS')
readRDS(H1.Sph.beta.revWT, 'RDS-files/H1.Sph.beta.revWT.RDS')
```

```{r}
summary(H1.Sph.beta.revWT)
```

```{r}
plot(H1.Sph.beta.revWT)
```

```{r}
# Bayesian R-squared
r2 <- bayes_R2(H1.Sph.beta.revWT)
print(r2)
```

```{r}
pp_check(H1.Sph.beta.revWT, ndraws = 100, type = 'dens_overlay')
```

```{r}
H1.Sph.beta.revWT.imp<-   brm(Sphagnum_beta/100 ~ Treatment + WT_total_days_below_sum + WT_consecutive_days_below_max + WT_mean + (1 | Location/Sublocation),
                   data=H1.Sph.revWT.imp,
                 Beta(link = "logit", link_phi = "log"),
                chains = 4, # nb of chains
                 iter = 4000, # nb of iterations, including burnin
                 warmup = 1000, # burnin
                 thin = 3,
                control = list(adapt_delta = 0.99, max_treedepth = 15))
                init = init_fun

saveRDS(H1.Sph.beta.revWT.imp, 'RDS-files/H1.Sph.beta.revWT.imp.RDS')
#readRDS(H1.Sph.beta, 'RDS-files/H1.Sph.beta.RDS')
```

```{r}
summary(H1.Sph.beta.revWT.imp)
```

```{r}
pp_check(H1.Sph.beta.revWT.imp, ndraws = 100, type = 'dens_overlay')
```

```{r}
H3.Sph.beta.revWT.imp<-   brm(Sphagnum_beta/100 ~ WT_total_days_below_sum + WT_consecutive_days_below_max + WT_mean + (1 | Location/Sublocation),
                   data=H1.Sph.revWT.imp,
                 Beta(link = "logit", link_phi = "log"),
                chains = 4, # nb of chains
                 iter = 4000, # nb of iterations, including burnin
                 warmup = 1000, # burnin
                 thin = 3,
                control = list(adapt_delta = 0.99, max_treedepth = 15))
                init = init_fun

# saveRDS(H3.Sph.beta.revWT.imp, 'RDS-files/H3.Sph.beta.revWT.imp.RDS')
readRDS(H3.Sph.beta.revWT.imp, 'RDS-files/H3.Sph.beta.revWT.imp.RDS')              
```

```{r}
summary(H3.Sph.beta.revWT.imp)
```

```{r}
pp_check(H3.Sph.beta.revWT.imp, ndraws = 100, type = 'dens_overlay')
```

```{r}
# Generate predictions from the models
pred_H1 <- posterior_predict(H1.Sph.beta.revWT.imp)
pred_H3 <- posterior_predict(H3.Sph.beta.revWT.imp)


#Compare variance explained by full model vs submodel
var_H1<- apply(pred_H1, 2, var)
var_H3 <- apply(pred_H3, 2, var)
```

```{r}
# Calculate variance explained
prop_var_Treatment <- 1 - var_H3 / var_H1

mean(prop_var_Treatment)
cat("Proportion of variance explained by Treatment: ", mean(prop_var_Treatment), "\n")

```

```{r}
loo_H1 <- loo(H1.Sph.beta.revWT.imp)
loo_H3 <- loo(H3.Sph.beta.revWT.imp)

loo_compare(loo_H1, loo_H3)
```

```{r}
# Create the pp_check plot
ppc_H1 <- pp_check(H1.Sph.beta.revWT.imp, ndraws = 100, type = 'dens_overlay')

# Add axis labels
ppc_H1 <- ppc_H1 + labs(x = "Proportion of Sphagnum cover", y = "Density")

# Save the plot to a file
ggsave(filename = '../figures/ppc_H1.revWT.imp.png', plot = ppc_H1)
ppc_H1
```

```{r}
# Extract posterior samples
posterior_samples <- as.data.frame(H1.Sph.beta.revWT.imp)

# List of variables of interest
variables <- c("b_Treatment", "b_WT_consecutive_days_below_max", 
               "b_WT_total_days_below_sum")

# Extracting posterior samples for the variables of interest
selected_columns <- colnames(posterior_samples)[grepl(paste(variables, collapse = "|"), colnames(posterior_samples))]

# Reshape data for ggplot2
posterior_data <- posterior_samples %>%
  pivot_longer(cols = all_of(selected_columns), names_to = "Variable", values_to = "Value")

# Rename variables for better y-axis labels
posterior_data$Variable <- recode(posterior_data$Variable, 
                                  "b_WT_consecutive_days_below_max" = "max consecutive days low WT",
                                  "b_WT_total_days_below_sum" = "total days low WT",
                                  "b_TreatmentS" = "Treatment M&S",
                                  'b_TreatmentM' = 'Treatment M')  

# Define x-axis limits to exclude extreme tails
x_limits <- c(-2.5, 5)  # Adjust these values based on your data

# Create the ridge plot
ridge_plot <- ggplot(posterior_data, aes(x = Value, y = Variable, fill = Variable)) +
  geom_density_ridges() +
  labs(x = "Posterior value", y = "Explanatory variable", title = "Posterior distributions of explanatory variables") +
  theme_ridges() +
  theme(legend.position = "none",
        plot.title = element_text(size = 14, hjust=0, vjust=1),
        axis.title.x = element_text(hjust = 0.5, vjust = 0.5),   # Move x-axis label to the left
    axis.title.y = element_text(margin = margin(t = 80, r = 10, b = 0, l = 0))) + # Move y-axis somewhat down
  coord_cartesian(xlim = x_limits) +
  scale_fill_brewer(palette = "PuOr")


# Save the plot
ggsave(filename = '../figures/treatment_posterior_distributions.H1.revWT.imp.png', plot = ridge_plot)
ridge_plot
```

Running any interaction models are definitely too complex for the data (I've tested, with models not converging and lots of warnings).
